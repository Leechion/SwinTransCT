Index: train.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import os\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.optim as optim\r\nfrom torch.utils.data import DataLoader\r\nfrom torch.utils.tensorboard import SummaryWriter\r\nfrom tqdm import tqdm\r\nimport math\r\nimport argparse\r\nimport numpy as np\r\nimport random\r\nfrom torchvision.utils import make_grid\r\n\r\n# 导入自定义模块（确保路径正确，若报错需调整导入路径）\r\nfrom loss import HybridLoss\r\nfrom dataset import CTDataset, get_pair_list  # 我的数据集类\r\nfrom model_improve import LDCTNet_Swin_improve                # 我的LDCTNet_Swin模型\r\nfrom Trans_model import LDCTNet256                # 你的LDCTNet_Swin模型\r\nfrom utils import ImageMetrics                # 指标计算模块（PSNR/SSIM/RMSE）\r\nfrom utils import TrainingRecorder                # 指标计算模块（PSNR/SSIM/RMSE）\r\n\r\n\r\ntorch.manual_seed(0)\r\nnp.random.seed(0)\r\nrandom.seed(0)\r\n\r\ndef save_image_grid(ld_img, nd_img, output_img, save_path, epoch):\r\n    \"\"\"\r\n    保存一行3列的图像对比图（仅取第一个样本，避免多样本干扰）\r\n    布局：低剂量输入 → 正常剂量标签 → 模型输出\r\n    Args:\r\n        ld_img: 低剂量CT输入 [B,1,H,W]\r\n        nd_img: 正常剂量CT标签 [B,1,H,W]\r\n        output_img: 模型输出 [B,1,H,W]\r\n        save_path: 图像保存目录\r\n        epoch: 当前epoch编号\r\n    \"\"\"\r\n    # 创建保存目录\r\n    os.makedirs(save_path, exist_ok=True)\r\n    \r\n    # 图像归一化到[0,1]（按单个样本归一化，保证亮度均衡）\r\n    def normalize(img):\r\n        img = img.detach().cpu()\r\n        img_min = img.min()\r\n        img_max = img.max()\r\n        return (img - img_min) / (img_max - img_min + 1e-8)  # 避免除零\r\n    \r\n    # 只取第一个样本（[B,1,H,W] → [1,H,W]），避免多样本混乱\r\n    ld_sample = ld_img[0:1]  # 取第一个样本，保持[1,1,H,W]格式\r\n    nd_sample = nd_img[0:1]\r\n    output_sample = output_img[0:1]\r\n    \r\n    # 归一化\r\n    ld_norm = normalize(ld_sample)\r\n    nd_norm = normalize(nd_sample)\r\n    output_norm = normalize(output_sample)\r\n    \r\n    # 拼接为一行3列：低剂量（左）→ 正常剂量（中）→ 模型输出（右）\r\n    # 按水平方向（dim=3）拼接，最终形状：[1,1,H, 3*W]\r\n    comparison_img = torch.cat([ld_norm, nd_norm, output_norm], dim=3)\r\n    \r\n    # 转换为PIL图像（适配保存）\r\n    from PIL import Image\r\n    # 处理维度：[1,1,H,3W] → [H,3W]（去掉批量和通道维度）\r\n    img_np = comparison_img.squeeze(0).squeeze(0).numpy()\r\n    img_np = (img_np * 255).astype(np.uint8)  # [0,1] → [0,255]\r\n    \r\n    # 保存文件（文件名含epoch，便于按顺序查看）\r\n    save_filename = f\"epoch_{epoch:03d}_comparison.png\"  # 03d补零（如005、010）\r\n    save_filepath = os.path.join(save_path, save_filename)\r\n    Image.fromarray(img_np, mode='L').save(save_filepath)  # mode='L'：灰度图格式\r\n    \r\n    # 打印保存日志\r\n    print(f\"[图像保存] 一行三列对比图已保存：{save_filepath}\")\r\n    print(f\"[图像布局] 左：低剂量输入 | 中：正常剂量标签 | 右：模型输出\")\r\ndef train_one_epoch(model, train_loader, criterion, optimizer, metrics_fn, device, epoch, writer):\r\n    \"\"\"训练一个epoch，同步计算损失和图像质量指标\"\"\"\r\n    model.train()\r\n    # 初始化累计变量（按样本数加权）\r\n    total_loss = 0.0\r\n    total_psnr = 0.0\r\n    total_ssim = 0.0\r\n    total_rmse = 0.0\r\n    total_samples = 0\r\n\r\n    # 进度条显示训练过程\r\n    progress_bar = tqdm(train_loader, desc=f\"[Train] Epoch {epoch:3d}\", unit=\"batch\")\r\n    for batch_idx, (ld_img, nd_img) in enumerate(progress_bar):\r\n        # 数据移至设备（CPU/GPU）\r\n        ld_img = ld_img.to(device, non_blocking=True)  # 低剂量CT（输入）\r\n        nd_img = nd_img.to(device, non_blocking=True)  # 正常剂量CT（标签）\r\n        batch_size = ld_img.size(0)\r\n        total_samples += batch_size\r\n\r\n        # 1. 清零梯度\r\n        optimizer.zero_grad()\r\n\r\n        # 2. 前向传播\r\n        outputs = model(ld_img)\r\n\r\n        # 3. 计算损失和指标\r\n        loss = criterion(outputs, nd_img)\r\n        metrics = metrics_fn(outputs, nd_img)  # 一次性获取PSNR/SSIM/RMSE\r\n\r\n        # 4. 反向传播与参数更新\r\n        loss.backward()\r\n        optimizer.step()  # 更新权重\r\n\r\n        # 5. 累计损失和指标\r\n        total_loss += loss.item() * batch_size\r\n        total_psnr += metrics[\"psnr\"] * batch_size\r\n        total_ssim += metrics[\"ssim\"] * batch_size\r\n        total_rmse += metrics[\"rmse\"] * batch_size\r\n\r\n        # 6. 实时更新进度条（显示当前batch的损失和PSNR）\r\n        progress_bar.set_postfix({\r\n            \"batch_loss\": f\"{loss.item():.6f}\",\r\n            \"batch_psnr\": f\"{metrics['psnr']:.2f}\",\r\n            \"batch_ssim\": f\"{metrics['ssim']:.4f}\"\r\n        })\r\n\r\n        # 7. 记录batch级日志（每10个batch写一次TensorBoard）\r\n        if (batch_idx + 1) % 10 == 0:\r\n            global_step = epoch * len(train_loader) + batch_idx\r\n            writer.add_scalar(\"Train/Batch_Loss\", loss.item(), global_step)\r\n            writer.add_scalar(\"Train/Batch_PSNR\", metrics[\"psnr\"], global_step)\r\n            writer.add_scalar(\"Train/Batch_SSIM\", metrics[\"ssim\"], global_step)\r\n            writer.add_scalar(\"Train/Batch_RMSE\", metrics[\"rmse\"], global_step)\r\n\r\n    # 8. 计算epoch级平均指标\r\n    avg_loss = total_loss / total_samples\r\n    avg_psnr = total_psnr / total_samples\r\n    avg_ssim = total_ssim / total_samples\r\n    avg_rmse = total_rmse / total_samples\r\n\r\n    # 9. 记录epoch级日志（写入TensorBoard）\r\n    writer.add_scalar(\"Train/Epoch_Loss\", avg_loss, epoch)\r\n    writer.add_scalar(\"Train/Epoch_PSNR\", avg_psnr, epoch)\r\n    writer.add_scalar(\"Train/Epoch_SSIM\", avg_ssim, epoch)\r\n    writer.add_scalar(\"Train/Epoch_RMSE\", avg_rmse, epoch)\r\n\r\n    return {\r\n        \"loss\": avg_loss,\r\n        \"psnr\": avg_psnr,\r\n        \"ssim\": avg_ssim,\r\n        \"rmse\": avg_rmse\r\n    }\r\n\r\n\r\ndef validate(model, val_loader, criterion, metrics_fn, device, epoch, writer):\r\n    \"\"\"验证模型，计算损失和指标，同步记录图像对比\"\"\"\r\n    model.eval()\r\n    # 初始化累计变量\r\n    total_loss = 0.0\r\n    total_psnr = 0.0\r\n    total_ssim = 0.0\r\n    total_rmse = 0.0\r\n    total_samples = 0\r\n\r\n    # 关闭梯度计算（加速验证，避免内存占用）\r\n    with torch.no_grad():\r\n        progress_bar = tqdm(val_loader, desc=f\"[Val]   Epoch {epoch:3d}\", unit=\"batch\")\r\n        for batch_idx, (ld_img, nd_img) in enumerate(progress_bar):\r\n            ld_img = ld_img.to(device, non_blocking=True)\r\n            nd_img = nd_img.to(device, non_blocking=True)\r\n            batch_size = ld_img.size(0)\r\n            total_samples += batch_size\r\n\r\n            # 1. 前向传播\r\n            outputs = model(ld_img)\r\n\r\n            # 2. 计算损失和指标\r\n            loss = criterion(outputs, nd_img)\r\n            metrics = metrics_fn(outputs, nd_img)\r\n\r\n            # 3. 累计损失和指标\r\n            total_loss += loss.item() * batch_size\r\n            total_psnr += metrics[\"psnr\"] * batch_size\r\n            total_ssim += metrics[\"ssim\"] * batch_size\r\n            total_rmse += metrics[\"rmse\"] * batch_size\r\n\r\n            # 4. 实时更新进度条\r\n            progress_bar.set_postfix({\r\n                \"batch_loss\": f\"{loss.item():.6f}\",\r\n                \"batch_psnr\": f\"{metrics['psnr']:.2f}\",\r\n                \"batch_ssim\": f\"{metrics['ssim']:.4f}\"\r\n            })\r\n\r\n            # 5. 记录验证集图像对比（每5个epoch，仅取第一个batch的第一张图）\r\n            if epoch % 5 == 0 and batch_idx == 0:\r\n                # 图像归一化到[0,1]（TensorBoard显示需要）\r\n                def normalize_img(img_tensor):\r\n                    img = img_tensor.cpu().numpy()[0, 0]  # (B,1,H,W) → (H,W)\r\n                    img_min, img_max = img.min(), img.max()\r\n                    return (img - img_min) / (img_max - img_min + 1e-8)  # 避免除零\r\n\r\n                # 提取并归一化3张图：低剂量输入、正常剂量标签、模型输出\r\n                ld_img_norm = normalize_img(ld_img)\r\n                nd_img_norm = normalize_img(nd_img)\r\n                output_norm = normalize_img(outputs)\r\n\r\n                # 写入TensorBoard（三张图横向排列，便于对比）\r\n                writer.add_image(f\"Val/Epoch_{epoch}_LowDose\", ld_img_norm, epoch, dataformats=\"HW\")\r\n                writer.add_image(f\"Val/Epoch_{epoch}_FullDose\", nd_img_norm, epoch, dataformats=\"HW\")\r\n                writer.add_image(f\"Val/Epoch_{epoch}_ModelOutput\", output_norm, epoch, dataformats=\"HW\")\r\n\r\n    # 6. 计算验证集epoch级平均指标\r\n    avg_loss = total_loss / total_samples\r\n    avg_psnr = total_psnr / total_samples\r\n    avg_ssim = total_ssim / total_samples\r\n    avg_rmse = total_rmse / total_samples\r\n\r\n    # 7. 记录验证集epoch级日志\r\n    writer.add_scalar(\"Val/Epoch_Loss\", avg_loss, epoch)\r\n    writer.add_scalar(\"Val/Epoch_PSNR\", avg_psnr, epoch)\r\n    writer.add_scalar(\"Val/Epoch_SSIM\", avg_ssim, epoch)\r\n    writer.add_scalar(\"Val/Epoch_RMSE\", avg_rmse, epoch)\r\n\r\n    return {\r\n        \"loss\": avg_loss,\r\n        \"psnr\": avg_psnr,\r\n        \"ssim\": avg_ssim,\r\n        \"rmse\": avg_rmse\r\n    }\r\n\r\n\r\ndef main(args):\r\n    # 1. 设备配置（优先GPU，无GPU则用CPU）\r\n    device = torch.device(\r\n        f\"cuda:{args.gpu}\" if torch.cuda.is_available() and args.gpu >= 0 else \"cpu\"\r\n    )\r\n    print(f\"=\" * 60)\r\n    print(f\"训练配置：\")\r\n    print(f\"  设备: {device}\")\r\n    print(f\"  数据集根目录: {args.data_dir}\")\r\n    print(f\"  训练轮数: {args.epochs}\")\r\n    print(f\"  批次大小: {args.batch_size}\")\r\n    print(f\"  初始学习率: {args.lr}\")\r\n    print(f\"  日志保存目录: {args.log_dir}\")\r\n    print(f\"  模型保存目录: {args.save_dir}\")\r\n    print(f\"=\" * 60)\r\n\r\n    # 2. 加载数据集（适配256×256图像）\r\n    print(\"\\n[1/5] 加载数据集...\")\r\n    # 生成训练/验证集图像对列表\r\n    train_pairs = get_pair_list(args.data_dir, split=\"train\")\r\n    val_pairs = get_pair_list(args.data_dir, split=\"val\")\r\n    # 初始化数据集（指定目标尺寸256×256）\r\n    train_dataset = CTDataset(train_pairs, target_size=256)\r\n    val_dataset = CTDataset(val_pairs, target_size=256)\r\n    # 构建DataLoader（多线程加载，pin_memory加速GPU传输）\r\n    train_loader = DataLoader(\r\n        train_dataset,\r\n        batch_size=args.batch_size,\r\n        shuffle=True,\r\n        num_workers=args.num_workers,\r\n        pin_memory=True,\r\n        drop_last=True  # 丢弃最后一个不完整的batch\r\n    )\r\n    val_loader = DataLoader(\r\n        val_dataset,\r\n        batch_size=args.batch_size,\r\n        shuffle=False,\r\n        num_workers=args.num_workers,\r\n        pin_memory=True,\r\n        drop_last=False\r\n    )\r\n    print(f\"  训练集：{len(train_dataset)} 样本 | {len(train_loader)} 批次\")\r\n    print(f\"  验证集：{len(val_dataset)} 样本 | {len(val_loader)} 批次\")\r\n    print(f\"  图像尺寸：{train_dataset[0][0].shape}（已Resize到256×256）\")\r\n\r\n    # 3. 初始化模型、损失函数、优化器、指标计算器\r\n    print(\"\\n[2/5] 初始化模型与工具...\")\r\n\r\n    ########################################################################################################\r\n    # 初始化模型（TransCT模型）\r\n    # model = LDCTNet256().to(device)\r\n    \r\n   \r\n    # 初始化LDCTNet_Swin（输入尺寸256×256，与数据集匹配）\r\n    # model = LDCTNet_Swin(\r\n    #     input_size=(256, 256),\r\n    #     base_channels=16,\r\n    #     swin_window_size=7,\r\n    #     swin_num_heads=8\r\n    # ).to(device)\r\n    model = LDCTNet_Swin_improve().to(device)\r\n    # 打印模型信息\r\n    print(f\"模型参数数量: {sum(p.numel() for p in model.parameters())}\")\r\n    print(f\"模型结构:\")\r\n    print(model)\r\n    #############################################################################################################\r\n\r\n\r\n    # 损失函数（MSE适合CT剂量恢复，可后续替换为MSE+SSIM混合损失）\r\n    criterion = HybridLoss().to(device)\r\n    \r\n    # 优化器（Adam + 权重衰减防过拟合）\r\n    optimizer = optim.Adam(\r\n        model.parameters(),\r\n        lr=args.lr,\r\n        weight_decay=1e-5  # 权重衰减系数，可根据需求调整\r\n    )\r\n    # 学习率调度器（验证损失不下降时降低学习率）\r\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\r\n        optimizer,\r\n        mode=\"min\",          # 基于\"验证损失\"最小化调整\r\n        factor=0.5,          # 学习率降低为原来的1/2\r\n        patience=3,          # 连续3个epoch无改善则调整\r\n        min_lr=1e-7          # 学习率下限\r\n    )\r\n    # 指标计算器（data_range需与预处理后图像范围匹配，这里假设[0,1]）\r\n    metrics_fn = ImageMetrics(data_range=1.0).to(device)\r\n\r\n    # 4. 日志与模型保存配置\r\n    print(\"\\n[3/5] 配置日志与模型保存...\")\r\n    # 创建日志和模型保存目录（不存在则自动创建）\r\n    os.makedirs(args.log_dir, exist_ok=True)\r\n    os.makedirs(args.save_dir, exist_ok=True)\r\n    # 初始化TensorBoard writer\r\n    writer = SummaryWriter(log_dir=args.log_dir)\r\n\r\n    # 新增：初始化训练记录器（保存到log_dir下的metrics.csv）\r\n    recorder = TrainingRecorder(\r\n        save_path=os.path.join(args.log_dir, \"training_metrics.csv\"),\r\n        args=args  # 传入训练参数，记录到CSV头部\r\n    )\r\n\r\n    # 最佳模型记录（用验证集PSNR作为评判标准，PSNR越高模型越好）\r\n    best_val_psnr = 0.0\r\n    best_val_epoch = 0\r\n\r\n    # 5. 加载预训练模型（可选，支持断点续训）\r\n    if args.resume != \"\":\r\n        print(f\"\\n[4/5] 加载预训练模型：{args.resume}\")\r\n        if os.path.isfile(args.resume):\r\n            checkpoint = torch.load(args.resume, map_location=device)\r\n            # 加载模型权重和优化器状态\r\n            model.load_state_dict(checkpoint[\"model_state_dict\"])\r\n            optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\r\n            # 恢复训练进度和最佳指标\r\n            start_epoch = checkpoint[\"epoch\"] + 1\r\n            best_val_psnr = checkpoint[\"best_val_psnr\"]\r\n            best_val_epoch = checkpoint[\"best_val_epoch\"]\r\n            print(f\"  恢复训练：从Epoch {start_epoch}开始\")\r\n            print(f\"  历史最佳：Epoch {best_val_epoch} | Val PSNR: {best_val_psnr:.2f}\")\r\n        else:\r\n            print(f\"  警告：未找到预训练模型文件，将从头开始训练\")\r\n            start_epoch = 0\r\n    else:\r\n        start_epoch = 0\r\n\r\n    # 6. 训练主循环\r\n    print(\"\\n[5/5] 开始训练...\")\r\n    for epoch in range(start_epoch, args.epochs):\r\n        # 训练一个epoch\r\n        train_metrics = train_one_epoch(\r\n            model, train_loader, criterion, optimizer, metrics_fn, device, epoch, writer\r\n        )\r\n        # 验证一个epoch\r\n        val_metrics = validate(\r\n            model, val_loader, criterion, metrics_fn, device, epoch, writer\r\n        )\r\n        # 调整学习率（基于验证集损失）\r\n        scheduler.step(val_metrics[\"loss\"])\r\n\r\n\r\n        # 新增：记录当前epoch的学习率（用于CSV保存）\r\n        current_lr = optimizer.param_groups[0][\"lr\"]\r\n    # --------------------------\r\n    # 新增：本地保存图像对比网格\r\n    # --------------------------\r\n        save_freq = 3  # 每5个epoch保存一次（可调整为1、10等）\r\n        if epoch % save_freq == 0:\r\n        # 获取第一个batch的第一个样本\r\n         ld_sample, nd_sample = val_first_batch\r\n         ld_sample = ld_sample.to(device, non_blocking=True)\r\n         nd_sample = nd_sample.to(device, non_blocking=True)\r\n        \r\n        # 模型推理（仅对第一个样本）\r\n         model.eval()\r\n         with torch.no_grad():\r\n            output_sample = model(ld_sample)\r\n        \r\n        # 调用保存函数（保存路径：log_dir/images）\r\n         save_image_grid(\r\n            ld_img=ld_sample,\r\n            nd_img=nd_sample,\r\n            output_img=output_sample,\r\n            save_path=os.path.join(args.image_dir, \"images\"),  # 保存目录\r\n            epoch=epoch\r\n        )\r\n    # --------------------------\r\n    # 新增代码结束\r\n    # --------------------------\r\n\r\n\r\n        # 7. 控制台打印epoch总结（格式化输出，清晰易读）\r\n        print(f\"\\n\" + \"=\" * 80)\r\n        print(f\"Epoch {epoch:3d}/{args.epochs-1:3d} | 训练集指标：\")\r\n        print(f\"  损失：{train_metrics['loss']:.6f} | PSNR：{train_metrics['psnr']:.2f} dB\")\r\n        print(f\"  SSIM：{train_metrics['ssim']:.4f} | RMSE：{train_metrics['rmse']:.6f}\")\r\n        print(f\"Epoch {epoch:3d}/{args.epochs-1:3d} | 验证集指标：\")\r\n        print(f\"  损失：{val_metrics['loss']:.6f} | PSNR：{val_metrics['psnr']:.2f} dB\")\r\n        print(f\"  SSIM：{val_metrics['ssim']:.4f} | RMSE：{val_metrics['rmse']:.6f}\")\r\n        print(f\"=\" * 80)\r\n\r\n        # 新增：调用recorder记录指标到CSV\r\n        recorder.record_epoch(epoch, train_metrics, val_metrics, current_lr)\r\n\r\n        # 8. 保存最佳模型（验证集PSNR更高则更新）\r\n        if val_metrics[\"psnr\"] > best_val_psnr:\r\n            best_val_psnr = val_metrics[\"psnr\"]\r\n            best_val_epoch = epoch\r\n            # 保存模型权重、优化器状态、训练进度\r\n            checkpoint = {\r\n                \"epoch\": epoch,\r\n                \"model_state_dict\": model.state_dict(),\r\n                \"optimizer_state_dict\": optimizer.state_dict(),\r\n                \"best_val_psnr\": best_val_psnr,\r\n                \"best_val_epoch\": best_val_epoch,\r\n                \"val_metrics\": val_metrics  # 保存当前验证集指标\r\n            }\r\n            best_model_path = os.path.join(args.save_dir, \"best_model.pth\")\r\n            torch.save(checkpoint, best_model_path)\r\n            print(f\"[保存最佳模型] Epoch {epoch} | 验证集PSNR：{best_val_psnr:.2f} dB\")\r\n\r\n        # 9. 保存定期 checkpoint（每10个epoch保存一次，便于回溯）\r\n        if (epoch + 1) % 50 == 0:\r\n            checkpoint = {\r\n                \"epoch\": epoch,\r\n                \"model_state_dict\": model.state_dict(),\r\n                \"optimizer_state_dict\": optimizer.state_dict(),\r\n                \"val_metrics\": val_metrics\r\n            }\r\n            checkpoint_path = os.path.join(args.save_dir, f\"checkpoint_epoch_{epoch}.pth\")\r\n            torch.save(checkpoint, checkpoint_path)\r\n            print(f\"[保存定期 checkpoint] Epoch {epoch} | 路径：{checkpoint_path}\")\r\n\r\n    # 10. 训练结束：打印总结并关闭writer\r\n    print(\"\\n\" + \"=\" * 60)\r\n    print(\"训练完成！\")\r\n    print(f\"最佳模型：Epoch {best_val_epoch} | 验证集PSNR：{best_val_psnr:.2f} dB\")\r\n    print(f\"最佳模型路径：{os.path.join(args.save_dir, 'best_model.pth')}\")\r\n    writer.close()\r\n    print(\"TensorBoard 日志已保存在：{}\".format(args.log_dir))\r\n\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument(\"--data_dir\", type=str, default=\"./data\")\r\n    parser.add_argument(\"--epochs\", type=int, default=300)\r\n    parser.add_argument(\"--batch_size\", type=int, default=8)\r\n    parser.add_argument(\"--lr\", type=float, default=1e-4)\r\n    parser.add_argument(\"--log_dir\", type=str, default=\"./logs\")\r\n    parser.add_argument(\"--image_dir\", type=str, default=\"./image_loader\")\r\n    parser.add_argument(\"--save_dir\", type=str, default=\"./checkpoints\")\r\n    parser.add_argument(\"--num_workers\", type=int, default=4)\r\n    parser.add_argument(\"--gpu\", type=int, default=0)\r\n    parser.add_argument(\"--resume\", type=str, default=\"\")\r\n    args = parser.parse_args()\r\n    main(args)\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/train.py b/train.py
--- a/train.py	(revision 9caef339bacc0f7b55d0493a539297f0864e5cd0)
+++ b/train.py	(date 1762439714084)
@@ -9,7 +9,7 @@
 import argparse
 import numpy as np
 import random
-from torchvision.utils import make_grid
+
 
 # 导入自定义模块（确保路径正确，若报错需调整导入路径）
 from loss import HybridLoss
@@ -371,6 +371,7 @@
     # 新增：本地保存图像对比网格
     # --------------------------
         save_freq = 3  # 每5个epoch保存一次（可调整为1、10等）
+        val_first_batch = next(iter(val_loader))
         if epoch % save_freq == 0:
         # 获取第一个batch的第一个样本
          ld_sample, nd_sample = val_first_batch
Index: loss.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\n\r\nclass HybridLoss(nn.Module):\r\n    \"\"\"\r\n    Hybrid Loss for CT reconstruction:\r\n    L = 0.7*L1 + 0.2*(1-SSIM) + 0.1*EdgeLoss\r\n    输入输出尺寸: [B, 1, H, W]\r\n    \"\"\"\r\n    def __init__(self, alpha=0.7, beta=0.2, gamma=0.1,\r\n                 window_size=11, window_sigma=1.5, device='cpu'):\r\n        super(HybridLoss, self).__init__()\r\n        self.alpha = alpha\r\n        self.beta = beta\r\n        self.gamma = gamma\r\n        self.window_size = window_size\r\n        self.device = device\r\n\r\n        # 高斯卷积核，用于 SSIM\r\n        self.gaussian_kernel = self.create_gaussian_kernel(window_size, window_sigma)\r\n\r\n        # Sobel 卷积核，用于 Edge Loss\r\n        self.sobel_x = torch.tensor([[1,0,-1],[2,0,-2],[1,0,-1]], dtype=torch.float32, device=device).view(1,1,3,3)\r\n        self.sobel_y = torch.tensor([[1,2,1],[0,0,0],[-1,-2,-1]], dtype=torch.float32, device=device).view(1,1,3,3)\r\n\r\n    def create_gaussian_kernel(self, size, sigma):\r\n        coords = torch.arange(size, dtype=torch.float32) - size//2\r\n        g = torch.exp(-(coords**2)/(2*sigma**2))\r\n        g = g / g.sum()\r\n        kernel_2d = g[:,None] @ g[None,:]  # 外积得到 2D\r\n        kernel_2d = kernel_2d.unsqueeze(0).unsqueeze(0)  # [1,1,H,W]\r\n        return kernel_2d\r\n\r\n    def ssim(self, img1, img2, C1=1e-4, C2=9e-4):\r\n        \"\"\"计算 SSIM，输入 [B,1,H,W]\"\"\"\r\n        mu1 = F.conv2d(img1, self.gaussian_kernel, padding=self.window_size//2)\r\n        mu2 = F.conv2d(img2, self.gaussian_kernel, padding=self.window_size//2)\r\n        mu1_sq = mu1**2\r\n        mu2_sq = mu2**2\r\n        mu1_mu2 = mu1*mu2\r\n\r\n        sigma1_sq = F.conv2d(img1*img1, self.gaussian_kernel, padding=self.window_size//2) - mu1_sq\r\n        sigma2_sq = F.conv2d(img2*img2, self.gaussian_kernel, padding=self.window_size//2) - mu2_sq\r\n        sigma12 = F.conv2d(img1*img2, self.gaussian_kernel, padding=self.window_size//2) - mu1_mu2\r\n\r\n        ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2)) / ((mu1_sq+mu2_sq + C1)*(sigma1_sq+sigma2_sq + C2))\r\n        return ssim_map.mean()\r\n\r\n    def edge_loss(self, pred, target):\r\n        \"\"\"基于 Sobel 边缘的 L1 损失\"\"\"\r\n        gx_pred = F.conv2d(pred, self.sobel_x, padding=1)\r\n        gy_pred = F.conv2d(pred, self.sobel_y, padding=1)\r\n        gx_target = F.conv2d(target, self.sobel_x, padding=1)\r\n        gy_target = F.conv2d(target, self.sobel_y, padding=1)\r\n        loss = F.l1_loss(gx_pred, gx_target) + F.l1_loss(gy_pred, gy_target)\r\n        return loss\r\n\r\n    def forward(self, pred, target):\r\n        l1 = F.l1_loss(pred, target)\r\n        ssim_loss = 1 - self.ssim(pred, target)\r\n        edge = self.edge_loss(pred, target)\r\n        loss = self.alpha * l1 + self.beta * ssim_loss + self.gamma * edge\r\n        return loss\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/loss.py b/loss.py
--- a/loss.py	(revision 9caef339bacc0f7b55d0493a539297f0864e5cd0)
+++ b/loss.py	(date 1762439714077)
@@ -9,7 +9,7 @@
     输入输出尺寸: [B, 1, H, W]
     """
     def __init__(self, alpha=0.7, beta=0.2, gamma=0.1,
-                 window_size=11, window_sigma=1.5, device='cpu'):
+                 window_size=11, window_sigma=1.5, device='gpu'):
         super(HybridLoss, self).__init__()
         self.alpha = alpha
         self.beta = beta
