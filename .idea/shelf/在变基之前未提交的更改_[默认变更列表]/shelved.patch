Index: SwinTransCT-main/plot.py
===================================================================
diff --git a/SwinTransCT-main/plot.py b/SwinTransCT-main/plot.py
deleted file mode 100644
--- a/SwinTransCT-main/plot.py	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
+++ /dev/null	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
@@ -1,122 +0,0 @@
-import argparse
-import os
-
-import matplotlib.pyplot as plt
-import pandas as pd
-
-# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆé¿å…ä¸­æ–‡ä¹±ç ï¼‰
-plt.rcParams['font.sans-serif'] = ['SimHei']  # Windowsï¼šSimHei / Macï¼šArial Unicode MS
-plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
-
-
-def plot_training_metrics(csv_path, save_dir="metrics_plots", figsize=(15, 10), dpi=300):
-    """
-    ä»CSVæ–‡ä»¶ç»˜åˆ¶è®­ç»ƒ/éªŒè¯æŒ‡æ ‡æ›²çº¿å›¾
-    Args:
-        csv_path: CSVæŒ‡æ ‡æ–‡ä»¶è·¯å¾„ï¼ˆtraining_metrics.csvï¼‰
-        save_dir: å›¾è¡¨ä¿å­˜ç›®å½•
-        figsize: å›¾è¡¨å°ºå¯¸
-        dpi: ä¿å­˜å›¾ç‰‡çš„åˆ†è¾¨ç‡ï¼ˆ300ä¸ºé«˜æ¸…ï¼Œé€‚åˆè®ºæ–‡ï¼‰
-    """
-    # 1. è¯»å–CSVæ–‡ä»¶
-    if not os.path.exists(csv_path):
-        print(f"é”™è¯¯ï¼šæœªæ‰¾åˆ°CSVæ–‡ä»¶ {csv_path}")
-        return
-
-    df = pd.read_csv(csv_path)
-    print(f"æˆåŠŸè¯»å–CSVæ–‡ä»¶ï¼Œå…± {len(df)} ä¸ªepochçš„æŒ‡æ ‡")
-    print("CSVæ–‡ä»¶åˆ—åï¼š", df.columns.tolist())
-
-    # 2. åˆ›å»ºä¿å­˜ç›®å½•
-    os.makedirs(save_dir, exist_ok=True)
-
-    # 3. è®¾ç½®å›¾è¡¨æ ·å¼ï¼ˆä¸“ä¸šç¾è§‚ï¼‰
-    plt.style.use('default')
-    colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D']  # ä¸“ä¸šé…è‰²æ–¹æ¡ˆ
-    markers = ['o', 's', '^', 'D']  # æ ‡è®°ç‚¹æ ·å¼ï¼ˆå¯é€‰ï¼‰
-    line_width = 2.0
-    marker_size = 4
-
-    # 4. åˆ›å»º2x2å­å›¾ï¼ˆåˆ†åˆ«æ˜¾ç¤º4ä¸ªæŒ‡æ ‡ï¼‰
-    fig, axes = plt.subplots(2, 2, figsize=figsize)
-    fig.suptitle('è®­ç»ƒè¿‡ç¨‹æŒ‡æ ‡å˜åŒ–æ›²çº¿', fontsize=16, fontweight='bold', y=0.98)
-
-    # å®šä¹‰è¦ç»˜åˆ¶çš„æŒ‡æ ‡ï¼ˆä¸CSVåˆ—åå¯¹åº”ï¼‰
-    metrics_config = [
-        # (å­å›¾ä½ç½®, æŒ‡æ ‡åç§°, è®­ç»ƒé›†åˆ—å, éªŒè¯é›†åˆ—å, yè½´æ ‡ç­¾)
-        ((0, 0), 'æŸå¤±å€¼ (Loss)', 'train_loss', 'val_loss', 'æŸå¤±å€¼'),
-        ((0, 1), 'å³°å€¼ä¿¡å™ªæ¯” (PSNR)', 'train_psnr', 'val_psnr', 'PSNR (dB)'),
-        ((1, 0), 'ç»“æ„ç›¸ä¼¼æ€§ (SSIM)', 'train_ssim', 'val_ssim', 'SSIM'),
-        ((1, 1), 'å‡æ–¹æ ¹è¯¯å·® (RMSE)', 'train_rmse', 'val_rmse', 'RMSE')
-    ]
-
-    # 5. é€ä¸ªç»˜åˆ¶æŒ‡æ ‡æ›²çº¿
-    for (row, col), title, train_col, val_col, ylabel in metrics_config:
-        ax = axes[row, col]
-
-        # ç»˜åˆ¶è®­ç»ƒé›†æ›²çº¿
-        ax.plot(
-            df['epoch'], df[train_col],
-            color=colors[0], linewidth=line_width, marker=markers[0], markersize=marker_size,
-            label=f'è®­ç»ƒé›†', alpha=0.8
-        )
-
-        # ç»˜åˆ¶éªŒè¯é›†æ›²çº¿
-        ax.plot(
-            df['epoch'], df[val_col],
-            color=colors[1], linewidth=line_width, marker=markers[1], markersize=marker_size,
-            label=f'éªŒè¯é›†', alpha=0.8
-        )
-
-        # è®¾ç½®å­å›¾æ ‡é¢˜å’Œæ ‡ç­¾
-        ax.set_title(title, fontsize=14, fontweight='bold', pad=10)
-        ax.set_xlabel('Epoch', fontsize=12)
-        ax.set_ylabel(ylabel, fontsize=12)
-
-        # æ·»åŠ ç½‘æ ¼ï¼ˆä¾¿äºè¯»å–æ•°å€¼ï¼‰
-        ax.grid(True, alpha=0.3, linestyle='--')
-
-        # æ·»åŠ å›¾ä¾‹
-        ax.legend(loc='best', fontsize=10)
-
-        # ä¼˜åŒ–åæ ‡è½´åˆ»åº¦
-        ax.tick_params(axis='both', which='major', labelsize=10)
-
-    # 6. è°ƒæ•´å­å›¾é—´è·ï¼ˆé¿å…é‡å ï¼‰
-    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
-
-    # 7. ä¿å­˜é«˜æ¸…å›¾ç‰‡ï¼ˆæ”¯æŒPNG/JPG/SVGæ ¼å¼ï¼‰
-    save_path_png = os.path.join(save_dir, 'training_metrics.png')
-    plt.savefig(save_path_png, dpi=dpi, bbox_inches='tight', facecolor='white')
-    print(f"å›¾è¡¨å·²ä¿å­˜ä¸ºï¼š{save_path_png}")
-
-    # å¯é€‰ï¼šä¿å­˜ä¸ºSVGçŸ¢é‡å›¾ï¼ˆæ— é™æ”¾å¤§ä¸å¤±çœŸï¼Œé€‚åˆè®ºæ–‡ï¼‰
-    save_path_svg = os.path.join(save_dir, 'training_metrics.svg')
-    plt.savefig(save_path_svg, bbox_inches='tight', facecolor='white')
-    print(f"çŸ¢é‡å›¾å·²ä¿å­˜ä¸ºï¼š{save_path_svg}")
-
-    # 8. æ˜¾ç¤ºå›¾è¡¨ï¼ˆå¯é€‰ï¼‰
-    plt.show()
-
-
-if __name__ == "__main__":
-    # è§£æå‘½ä»¤è¡Œå‚æ•°
-    parser = argparse.ArgumentParser(description='ç»˜åˆ¶è®­ç»ƒæŒ‡æ ‡æ›²çº¿å›¾')
-    parser.add_argument('--csv_path', type=str,
-                        default='/Users/lxxxx/Desktop/CODE/SwinCT/logs/training_metrics.csv')
-    parser.add_argument('--save_dir', type=str, default='metrics_plots',
-                        help='å›¾è¡¨ä¿å­˜ç›®å½•ï¼ˆé»˜è®¤ï¼šmetrics_plotsï¼‰')
-    parser.add_argument('--figsize', type=tuple, default=(15, 10),
-                        help='å›¾è¡¨å°ºå¯¸ï¼ˆé»˜è®¤ï¼š(15,10)ï¼‰')
-    parser.add_argument('--dpi', type=int, default=500,
-                        help='å›¾ç‰‡åˆ†è¾¨ç‡ï¼ˆé»˜è®¤ï¼š500ï¼Œè¶Šé«˜è¶Šæ¸…æ™°ï¼‰')
-
-    args = parser.parse_args()
-
-    # è¿è¡Œç»˜å›¾å‡½æ•°
-    plot_training_metrics(
-        csv_path=args.csv_path,
-        save_dir=args.save_dir,
-        figsize=args.figsize,
-        dpi=args.dpi
-    )
Index: SwinTransCT-main/dataset.py
===================================================================
diff --git a/SwinTransCT-main/dataset.py b/SwinTransCT-main/dataset.py
deleted file mode 100644
--- a/SwinTransCT-main/dataset.py	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
+++ /dev/null	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
@@ -1,74 +0,0 @@
-import os
-import random
-
-import torch
-import torchvision.transforms as T
-from PIL import Image
-from torch.utils.data import Dataset
-
-
-class CTDataset(Dataset):
-    """CTæ•°æ®é›†åŠ è½½å™¨ï¼šå¢å¼º + æ ‡å‡†åŒ– + æ›´å¿«åŠ è½½"""
-
-    def __init__(self, pair_list, target_size=256, augment=True):
-        self.samples = pair_list
-        self.target_size = target_size
-        self.augment = augment
-
-        # é¢„å®šä¹‰ torchvision å˜æ¢ç®¡é“ï¼ˆæ›´å¿«æ›´ç¨³å®šï¼‰
-        self.to_tensor = T.Compose([
-            T.Resize((target_size, target_size), interpolation=T.InterpolationMode.BILINEAR),
-            T.ToTensor(),  # è‡ªåŠ¨è½¬ [C,H,W], å¹¶é™¤ä»¥255
-        ])
-
-    def __len__(self):
-        return len(self.samples)
-
-    def __getitem__(self, idx):
-        ld_path, nd_path = self.samples[idx]
-
-        # è¯»å–
-        ld_img = Image.open(ld_path).convert('L')
-        nd_img = Image.open(nd_path).convert('L')
-
-        # Resize + è½¬Tensor
-        ld_tensor = self.to_tensor(ld_img)
-        nd_tensor = self.to_tensor(nd_img)
-
-        # ------------------------------
-        # âœ… æ•°æ®å¢å¼ºï¼ˆä»…åœ¨è®­ç»ƒé›†å¯ç”¨ï¼‰
-        # ------------------------------
-        if self.augment:
-            if random.random() < 0.5:
-                ld_tensor = torch.flip(ld_tensor, dims=[2])  # æ°´å¹³ç¿»è½¬
-                nd_tensor = torch.flip(nd_tensor, dims=[2])
-            if random.random() < 0.5:
-                ld_tensor = torch.flip(ld_tensor, dims=[1])  # å‚ç›´ç¿»è½¬
-                nd_tensor = torch.flip(nd_tensor, dims=[1])
-            if random.random() < 0.3:
-                angle = random.choice([-5, -3, 3, 5])
-                ld_tensor = T.functional.rotate(ld_tensor, angle)
-                nd_tensor = T.functional.rotate(nd_tensor, angle)
-
-        # ------------------------------------
-        # âœ… åƒç´ æ ‡å‡†åŒ–ï¼ˆå°†åƒç´ å½’ä¸€åŒ–åˆ° [0,1]ï¼‰
-        # ------------------------------------
-        ld_tensor = ld_tensor.clamp(0.0, 1.0)
-        nd_tensor = nd_tensor.clamp(0.0, 1.0)
-
-        return ld_tensor, nd_tensor
-
-
-# ------------------- æ•°æ®é›†åŠ è½½å‡½æ•° -------------------
-def get_pair_list(data_dir, split='train'):
-    ld_dir = os.path.join(data_dir, split, 'LD')
-    nd_dir = os.path.join(data_dir, split, 'ND')
-
-    ld_files = sorted([f for f in os.listdir(ld_dir) if f.lower().endswith('.png')])
-    nd_files = sorted([f for f in os.listdir(nd_dir) if f.lower().endswith('.png')])
-
-    pair_list = [
-        (os.path.join(ld_dir, ld_f), os.path.join(nd_dir, nd_f))
-        for ld_f, nd_f in zip(ld_files, nd_files)
-    ]
-    return pair_list
Index: SwinTransCT-main/struct33.py
===================================================================
diff --git a/SwinTransCT-main/struct33.py b/SwinTransCT-main/struct33.py
deleted file mode 100644
--- a/SwinTransCT-main/struct33.py	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
+++ /dev/null	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
@@ -1,27 +0,0 @@
-import h5py
-
-# æ›¿æ¢ä¸ºä½ çš„HDF5æ–‡ä»¶è·¯å¾„ï¼ˆå¤åˆ¶é”™è¯¯æç¤ºä¸­çš„è·¯å¾„ï¼‰
-hdf5_path = "/Users/lxxxx/Desktop/CODE/SwinCT/ground_truth_test/ground_truth_test_000.hdf5"
-
-
-def print_hdf5_full_structure(hdf5_path):
-    """å®Œæ•´æ‰“å°HDF5æ–‡ä»¶çš„æ‰€æœ‰åˆ†ç»„ã€æ•°æ®é›†å’Œå½¢çŠ¶"""
-    with h5py.File(hdf5_path, "r") as f:
-        print(f"=== HDF5æ–‡ä»¶ç»“æ„ï¼š{hdf5_path} ===")
-
-        def traverse(obj, path=""):
-            # æ‰“å°å½“å‰å¯¹è±¡çš„è·¯å¾„å’Œç±»å‹
-            if isinstance(obj, h5py.Group):
-                print(f"[åˆ†ç»„] {path}")
-                # é€’å½’éå†å­åˆ†ç»„/æ•°æ®é›†
-                for key in sorted(obj.keys()):
-                    traverse(obj[key], path + "/" + key)
-            elif isinstance(obj, h5py.Dataset):
-                # æ•°æ®é›†ï¼ˆé‡ç‚¹å…³æ³¨å½¢çŠ¶ä¸º (128, H, W) æˆ– (H, W, 128) çš„ï¼‰
-                print(f"[æ•°æ®é›†] {path} | å½¢çŠ¶ï¼š{obj.shape} | ç±»å‹ï¼š{obj.dtype}")
-
-        traverse(f)
-
-
-# è¿è¡ŒæŸ¥çœ‹ç»“æ„
-print_hdf5_full_structure(hdf5_path)
Index: SwinTransCT-main/split.py
===================================================================
diff --git a/SwinTransCT-main/split.py b/SwinTransCT-main/split.py
deleted file mode 100644
--- a/SwinTransCT-main/split.py	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
+++ /dev/null	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
@@ -1,140 +0,0 @@
-import os
-import shutil
-
-import numpy as np
-from tqdm import tqdm
-
-# --------------------------
-# 1. é…ç½®å‚æ•°ï¼ˆè¯·ç¡®è®¤è·¯å¾„æ­£ç¡®ï¼ï¼‰
-# --------------------------
-# åŸå§‹é…å¯¹æ•°æ®è·¯å¾„ï¼ˆæ‰¹é‡å¤„ç†ç”Ÿæˆçš„NDå’ŒLDæ–‡ä»¶å¤¹ï¼‰
-ND_RAW_DIR = "/Users/lxxxx/Desktop/CODE/SwinCT/ND_LD_Paired_Data/ND"
-LD_RAW_DIR = "/Users/lxxxx/Desktop/CODE/SwinCT/ND_LD_Paired_Data/LD"
-
-# åˆ’åˆ†åçš„æ•°æ®ä¿å­˜æ ¹è·¯å¾„ï¼ˆä¸åŸå§‹æ•°æ®åŒç›®å½•ï¼Œä¼šè‡ªåŠ¨åˆ›å»ºtrain/val/testï¼‰
-OUTPUT_ROOT = "/Users/lxxxx/Desktop/CODE/SwinCT/ND_LD_Paired_Data"
-
-# åˆ’åˆ†æ¯”ä¾‹ï¼ˆ8:1:1ï¼‰
-TRAIN_RATIO = 0.8
-VAL_RATIO = 0.1
-TEST_RATIO = 0.1
-
-# éšæœºç§å­ï¼ˆå›ºå®šï¼Œç¡®ä¿å¯å¤ç°ï¼‰
-SEED = 42
-np.random.seed(SEED)
-
-
-# --------------------------
-# 2. ä¿®å¤ï¼šå¼ºåˆ¶åˆ›å»ºæ‰€æœ‰ç›®æ ‡æ–‡ä»¶å¤¹ï¼ˆå…³é”®ï¼ï¼‰
-# --------------------------
-def create_all_dirs():
-    """æå‰åˆ›å»ºæ‰€æœ‰éœ€è¦çš„æ–‡ä»¶å¤¹ï¼Œé¿å…FileNotFoundError"""
-    # å®šä¹‰æ‰€æœ‰éœ€è¦çš„æ–‡ä»¶å¤¹è·¯å¾„
-    required_dirs = [
-        os.path.join(OUTPUT_ROOT, "train", "ND"),
-        os.path.join(OUTPUT_ROOT, "train", "LD"),
-        os.path.join(OUTPUT_ROOT, "val", "ND"),
-        os.path.join(OUTPUT_ROOT, "val", "LD"),
-        os.path.join(OUTPUT_ROOT, "test", "ND"),
-        os.path.join(OUTPUT_ROOT, "test", "LD")
-    ]
-
-    # å¾ªç¯åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆexist_ok=True è¡¨ç¤ºå·²å­˜åœ¨ä¹Ÿä¸æŠ¥é”™ï¼‰
-    for dir_path in required_dirs:
-        os.makedirs(dir_path, exist_ok=True)
-        print(f"å·²ç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨ï¼š{dir_path}")
-    print("\næ‰€æœ‰ç›®æ ‡æ–‡ä»¶å¤¹åˆ›å»ºå®Œæˆï¼")
-
-
-# --------------------------
-# 3. å¤åˆ¶é…å¯¹æ–‡ä»¶ï¼ˆé€»è¾‘ä¸å˜ï¼‰
-# --------------------------
-def copy_paired_images(image_filenames, split_type):
-    """å¤åˆ¶NDå’ŒLDé…å¯¹å›¾åƒåˆ°å¯¹åº”æ–‡ä»¶å¤¹"""
-    # æ‹¼æ¥æºè·¯å¾„å’Œç›®æ ‡è·¯å¾„
-    nd_src_dir = ND_RAW_DIR
-    ld_src_dir = LD_RAW_DIR
-    nd_dst_dir = os.path.join(OUTPUT_ROOT, split_type, "ND")
-    ld_dst_dir = os.path.join(OUTPUT_ROOT, split_type, "LD")
-
-    print(f"\nå¼€å§‹å¤åˆ¶{split_type}é›†ï¼ˆ{len(image_filenames)}å¯¹å›¾åƒï¼‰...")
-    for filename in tqdm(image_filenames):
-        # å¤åˆ¶NDå›¾åƒ
-        nd_src = os.path.join(nd_src_dir, filename)
-        nd_dst = os.path.join(nd_dst_dir, filename)
-        if os.path.exists(nd_src):  # é¿å…æºæ–‡ä»¶ä¸å­˜åœ¨æŠ¥é”™
-            shutil.copy2(nd_src, nd_dst)
-        else:
-            print(f"è­¦å‘Šï¼šNDæºæ–‡ä»¶ä¸å­˜åœ¨ â†’ {nd_src}")
-
-        # å¤åˆ¶å¯¹åº”LDå›¾åƒï¼ˆæ–‡ä»¶åä¸€è‡´ï¼‰
-        ld_src = os.path.join(ld_src_dir, filename)
-        ld_dst = os.path.join(ld_dst_dir, filename)
-        if os.path.exists(ld_src):
-            shutil.copy2(ld_src, ld_dst)
-        else:
-            print(f"è­¦å‘Šï¼šLDæºæ–‡ä»¶ä¸å­˜åœ¨ â†’ {ld_src}")
-
-
-# --------------------------
-# 4. æ ¸å¿ƒåˆ’åˆ†é€»è¾‘ï¼ˆè°ƒæ•´æ‰§è¡Œé¡ºåºï¼šå…ˆåˆ›å»ºæ–‡ä»¶å¤¹ï¼Œå†åˆ’åˆ†ï¼‰
-# --------------------------
-def split_train_val_test():
-    # ç¬¬ä¸€æ­¥ï¼šéªŒè¯åŸå§‹NDå’ŒLDæ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨ï¼Œä¸”æ–‡ä»¶æ•°é‡ä¸€è‡´
-    if not os.path.exists(ND_RAW_DIR):
-        raise FileNotFoundError(f"åŸå§‹NDæ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼è·¯å¾„ï¼š{ND_RAW_DIR}")
-    if not os.path.exists(LD_RAW_DIR):
-        raise FileNotFoundError(f"åŸå§‹LDæ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼è·¯å¾„ï¼š{LD_RAW_DIR}")
-
-    # ç»Ÿè®¡åŸå§‹æ–‡ä»¶æ•°é‡
-    nd_filenames = [f for f in os.listdir(ND_RAW_DIR) if f.endswith(".png")]
-    ld_filenames = [f for f in os.listdir(LD_RAW_DIR) if f.endswith(".png")]
-    nd_count = len(nd_filenames)
-    ld_count = len(ld_filenames)
-
-    if nd_count != ld_count:
-        raise ValueError(f"NDå’ŒLDæ–‡ä»¶æ•°é‡ä¸åŒ¹é…ï¼NDï¼š{nd_count}å¼ ï¼ŒLDï¼š{ld_count}å¼ ")
-    if nd_count == 0:
-        raise ValueError("åŸå§‹NDæ–‡ä»¶å¤¹ä¸­æ²¡æœ‰PNGå›¾åƒï¼è¯·æ£€æŸ¥æ‰¹é‡å¤„ç†æ˜¯å¦æˆåŠŸã€‚")
-
-    print(f"âœ… åŸå§‹æ•°æ®éªŒè¯é€šè¿‡ï¼šå…±{nd_count}å¯¹ND-LDå›¾åƒ")
-
-    # ç¬¬äºŒæ­¥ï¼šæå‰åˆ›å»ºæ‰€æœ‰ç›®æ ‡æ–‡ä»¶å¤¹ï¼ˆä¿®å¤æ ¸å¿ƒï¼‰
-    create_all_dirs()
-
-    # ç¬¬ä¸‰æ­¥ï¼šéšæœºæ‰“ä¹±æ–‡ä»¶åï¼Œä¿è¯åˆ’åˆ†å‡åŒ€
-    shuffled_indices = np.random.permutation(nd_count)
-    shuffled_filenames = [nd_filenames[i] for i in shuffled_indices]
-
-    # ç¬¬å››æ­¥ï¼šè®¡ç®—å„é›†æ•°é‡ï¼ˆé¿å…å°æ•°è¯¯å·®ï¼‰
-    train_count = int(nd_count * TRAIN_RATIO)
-    val_count = int(nd_count * VAL_RATIO)
-    test_count = nd_count - train_count - val_count  # å‰©ä½™å½’æµ‹è¯•é›†
-
-    print(f"\nğŸ“Š åˆ’åˆ†æ–¹æ¡ˆï¼š")
-    print(f"è®­ç»ƒé›†ï¼š{train_count}å¯¹ | éªŒè¯é›†ï¼š{val_count}å¯¹ | æµ‹è¯•é›†ï¼š{test_count}å¯¹")
-
-    # ç¬¬äº”æ­¥ï¼šåˆ†å‰²æ–‡ä»¶ååˆ—è¡¨
-    train_filenames = shuffled_filenames[:train_count]
-    val_filenames = shuffled_filenames[train_count:train_count + val_count]
-    test_filenames = shuffled_filenames[train_count + val_count:]
-
-    # ç¬¬å…­æ­¥ï¼šå¤åˆ¶æ–‡ä»¶
-    copy_paired_images(train_filenames, "train")
-    copy_paired_images(val_filenames, "val")
-    copy_paired_images(test_filenames, "test")
-
-    print("\nğŸ‰ åˆ’åˆ†å®Œæˆï¼")
-    print(f"è®­ç»ƒé›†ï¼š{os.path.join(OUTPUT_ROOT, 'train')}")
-    print(f"éªŒè¯é›†ï¼š{os.path.join(OUTPUT_ROOT, 'val')}")
-    print(f"æµ‹è¯•é›†ï¼š{os.path.join(OUTPUT_ROOT, 'test')}")
-
-
-# --------------------------
-# 5. æ‰§è¡Œåˆ’åˆ†
-# --------------------------
-if __name__ == "__main__":
-    try:
-        split_train_val_test()
-    except Exception as e:
-        print(f"\nâŒ åˆ’åˆ†å¤±è´¥ï¼é”™è¯¯ï¼š{str(e)}")
Index: SwinTransCT-main/Trans_model.py
===================================================================
diff --git a/SwinTransCT-main/Trans_model.py b/SwinTransCT-main/Trans_model.py
deleted file mode 100644
--- a/SwinTransCT-main/Trans_model.py	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
+++ /dev/null	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
@@ -1,237 +0,0 @@
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-
-
-class MultiHeadAttention(nn.Module):
-    """å¤šå¤´æ³¨æ„åŠ›æ¨¡å—"""
-
-    def __init__(self, d_model, nhead):
-        super(MultiHeadAttention, self).__init__()
-        self.d_model = d_model
-        self.nhead = nhead
-        self.head_dim = d_model // nhead
-        assert self.head_dim * nhead == d_model, "d_model must be divisible by nhead"
-        self.qkv_proj = nn.Linear(d_model, 3 * d_model)
-        self.out_proj = nn.Linear(d_model, d_model)
-
-    def forward(self, query, key=None, value=None):
-        if key is None:
-            key = query
-        if value is None:
-            value = key
-
-        b, n, d = query.shape
-        qkv = self.qkv_proj(query).view(b, n, 3, self.nhead, self.head_dim).permute(2, 0, 3, 1, 4)
-        q, k, v = qkv[0], qkv[1], qkv[2]  # [b, nhead, n, head_dim]
-
-        attn_scores = (q @ k.transpose(-2, -1)) / (self.head_dim ** 0.5)
-        attn_probs = F.softmax(attn_scores, dim=-1)
-        output = attn_probs @ v  # [b, nhead, n, head_dim]
-        output = output.transpose(1, 2).contiguous().view(b, n, d)  # åˆå¹¶å¤šå¤´
-        return self.out_proj(output)
-
-
-class FeedForward(nn.Module):
-    """å‰é¦ˆç½‘ç»œ"""
-
-    def __init__(self, d_model, dims):
-        super(FeedForward, self).__init__()
-        self.layers = nn.Sequential(
-            nn.Linear(d_model, dims[0]),
-            nn.LeakyReLU(inplace=True),
-            nn.Linear(dims[0], dims[1])
-        )
-
-    def forward(self, x):
-        return self.layers(x)
-
-
-class ResidualConnection(nn.Module):
-    """æ®‹å·®è¿æ¥ï¼ˆæŒ‰ä½ åŸæ„ï¼šnorm -> sublayer -> addï¼‰"""
-
-    def __init__(self, d_model):
-        super(ResidualConnection, self).__init__()
-        self.norm = nn.LayerNorm(d_model)
-
-    def forward(self, x, sublayer=None):
-        # sublayer åº”è¯¥æ˜¯ä¸€ä¸ª callableï¼Œæ¥å— norm(x) å¹¶è¿”å›åŒå½¢è¾“å‡º
-        if sublayer is not None:
-            return x + sublayer(self.norm(x))
-        # è‹¥æ²¡æœ‰ sublayerï¼Œå°±åšå¸¸è§„æ®‹å·®ï¼ˆx + norm(x)ï¼‰
-        return x + self.norm(x)
-
-
-# æ–°å¢ï¼šæŒ‰ä½ åŸå§‹æ„å›¾å®ç°çš„ç¼–ç å™¨å±‚ï¼ˆä¿ç•™ç»“æ„ï¼Œä¸æ”¹å˜è®¾è®¡ï¼‰
-class EncoderLayer(nn.Module):
-    def __init__(self, d_model, nhead):
-        super(EncoderLayer, self).__init__()
-        self.mha = MultiHeadAttention(d_model, nhead)
-        self.ff = FeedForward(d_model, [8 * d_model, d_model])
-        self.res1 = ResidualConnection(d_model)
-        self.res2 = ResidualConnection(d_model)
-
-    def forward(self, x):
-        # x: [B, seq_len, d_model]
-        x = self.res1(x, lambda y: self.mha(y))  # self-attention residual
-        x = self.res2(x, lambda y: self.ff(y))  # feed-forward residual
-        return x
-
-
-# æ–°å¢ï¼šè§£ç å™¨å±‚ï¼ˆå«è‡ªæ³¨æ„åŠ› + cross-attn + FFï¼‰
-class DecoderLayer(nn.Module):
-    def __init__(self, d_model, nhead):
-        super(DecoderLayer, self).__init__()
-        self.self_attn = MultiHeadAttention(d_model, nhead)
-        self.cross_attn = MultiHeadAttention(d_model, nhead)
-        self.ff = FeedForward(d_model, [8 * d_model, d_model])
-        self.res1 = ResidualConnection(d_model)
-        self.res2 = ResidualConnection(d_model)
-        self.res3 = ResidualConnection(d_model)
-
-    def forward(self, x, memory):
-        # x: [B, seq_x, d_model], memory: [B, seq_mem, d_model]
-        x = self.res1(x, lambda y: self.self_attn(y))  # self-attn
-        x = self.res2(x, lambda y: self.cross_attn(y, memory, memory))  # cross-attn(query=x, key/value=memory)
-        x = self.res3(x, lambda y: self.ff(y))  # FFN
-        return x
-
-
-class LDCTNet256(nn.Module):
-    def __init__(self):
-        super(LDCTNet256, self).__init__()
-        self.param = {
-            'nx': 256, 'ny': 256, 'numIterations': 50000, 'u_water': 0.0205,
-            'batchsize': 16, 'lr': 5e-5, 'retrain': False, 'epoch': 2500
-        }
-
-        # åˆ›å»ºé«˜æ–¯æ ¸ï¼ˆæ”¾ CPU ä¸Šï¼Œforward æ—¶å‘é€åˆ°è¾“å…¥è®¾å¤‡ï¼‰
-        self.gaussian_kernel = self._create_gaussian_kernel(11, 1.5)  # tensor on cpu
-
-        # LRè·¯å¾„ï¼ˆä½é¢‘ç‰¹å¾æå–ï¼‰
-        self.lr_conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=2, padding=2)  # 256â†’128
-        self.lr_conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=2)  # 128â†’64
-        self.lr_conv3 = nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=2)  # 64â†’32
-        self.lr_conv4 = nn.Conv2d(64, 256, kernel_size=5, stride=2, padding=2)  # 32â†’16
-
-        # HRè·¯å¾„ï¼ˆæ³¨æ„ï¼šspace_to_depth(block_size=8) å¯¹ 1ch è¾“å…¥ä¼šäº§ç”Ÿ 64chï¼‰
-        # å› æ­¤ç¬¬ä¸€å±‚ conv åº”æ¥æ”¶ 64 é€šé“
-        self.hr_process_convs = nn.Sequential(
-            nn.Conv2d(64, 256, kernel_size=3, padding=1),  # <-- 64 -> 256
-            nn.LeakyReLU(inplace=True),
-            nn.Conv2d(256, 256, kernel_size=3, padding=1),
-            nn.LeakyReLU(inplace=True),
-            nn.Conv2d(256, 256, kernel_size=3, padding=1),
-            nn.LeakyReLU(inplace=True)
-        )
-
-        # ç¼–ç å™¨ä¸è§£ç å™¨ï¼ˆä½¿ç”¨ä¸Šé¢æ–°å¢çš„ EncoderLayer / DecoderLayerï¼‰
-        self.encoder_layers = nn.ModuleList([EncoderLayer(256, 8) for _ in range(3)])
-        self.decoder_layers = nn.ModuleList([DecoderLayer(256, 8) for _ in range(3)])
-
-        # ç‰¹å¾èåˆå±‚
-        self.combine_convs1 = nn.Sequential(
-            nn.Conv2d(256, 256, kernel_size=3, padding=1),
-            nn.LeakyReLU(inplace=True),
-            nn.Conv2d(256, 256, kernel_size=3, padding=1),
-            nn.LeakyReLU(inplace=True)
-        )
-
-        # combine_convs2 çš„è¾“å…¥é€šé“åº”å½“ä¸ x_hr å’Œ x32_lr çš„é€šé“ä¸€è‡´ï¼ˆä¸¤è€…éƒ½æ˜¯ 64chï¼‰
-        self.combine_convs2 = nn.Sequential(
-            nn.Conv2d(64, 128, kernel_size=3, padding=1),  # <-- æ”¹ä¸º 64 è¾“å…¥
-            nn.LeakyReLU(inplace=True),
-            nn.Conv2d(128, 64, kernel_size=3, padding=1),
-            nn.LeakyReLU(inplace=True)
-        )
-
-        # è¾“å‡ºå±‚
-        self.final_conv = nn.Conv2d(1, 1, kernel_size=3, padding=1)
-
-        # åˆå§‹åŒ–æƒé‡
-        self._initialize_weights()
-
-    def _create_gaussian_kernel(self, size, sigma):
-        """åˆ›å»ºé«˜æ–¯æ ¸ï¼ˆè¿”å› CPU tensorï¼Œforward æ—¶å† .to(device)ï¼‰"""
-        coords = torch.arange(size, dtype=torch.float32)
-        coords -= size // 2
-        y_coords, x_coords = torch.meshgrid(coords, coords, indexing='ij')
-        kernel = torch.exp(-(x_coords ** 2 + y_coords ** 2) / (2 * sigma ** 2))
-        kernel /= kernel.sum()
-        return kernel.view(1, 1, size, size)  # cpu tensor
-
-    def _initialize_weights(self):
-        for m in self.modules():
-            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
-                nn.init.xavier_normal_(m.weight)
-                if m.bias is not None:
-                    nn.init.constant_(m.bias, 0)
-
-    @staticmethod
-    def space_to_depth(x, block_size):
-        """å®ç° tf.space_to_depthï¼ˆæ›´å¥å£®çš„å®ç°ï¼‰"""
-        b, c, h, w = x.size()
-        assert h % block_size == 0 and w % block_size == 0
-        x = x.view(b, c, h // block_size, block_size, w // block_size, block_size)
-        x = x.permute(0, 3, 5, 1, 2, 4).contiguous()
-        x = x.view(b, c * (block_size ** 2), h // block_size, w // block_size)
-        return x
-
-    @staticmethod
-    def depth_to_space(x, block_size):
-        """å®ç° tf.depth_to_spaceï¼ˆæ›´ç›´è§‚ã€å¯è¯»ï¼‰"""
-        b, c, h, w = x.size()
-        assert c % (block_size ** 2) == 0, "channels must be divisible by block_size^2"
-        new_c = c // (block_size ** 2)
-        x = x.view(b, new_c, block_size, block_size, h, w)
-        # ç°åœ¨ç»´åº¦ (b, new_c, block_size, block_size, h, w)
-        x = x.permute(0, 1, 4, 2, 5, 3).contiguous()  # -> (b, new_c, h, block_size, w, block_size)
-        x = x.view(b, new_c, h * block_size, w * block_size)
-        return x
-
-    def forward(self, x):
-        """å‰å‘ä¼ æ’­ - å‡å®šè¾“å…¥ x æ˜¯ [B,1,256,256]"""
-        b, c, h, w = x.shape
-        assert c == 1 and h == 256 and w == 256, "Input must be grayscale 256x256"
-
-        # é«˜ä½é¢‘åˆ†ç¦»ï¼ˆæŠŠ kernel å‘é€åˆ°è¾“å…¥æ‰€åœ¨ deviceï¼‰
-        kernel = self.gaussian_kernel.repeat(c, 1, 1, 1).to(x.device)
-        img_LR = F.conv2d(x, kernel, padding=5, groups=c)
-        img_HR = x - img_LR
-
-        # LR è·¯å¾„
-        x128_lr = F.leaky_relu(self.lr_conv1(img_LR))
-        x64_lr = F.leaky_relu(self.lr_conv2(x128_lr))
-        x32_lr = F.leaky_relu(self.lr_conv3(x64_lr))
-        x16_lr = F.leaky_relu(self.lr_conv4(x32_lr))  # [B,256,16,16]
-
-        # ç¼–ç å™¨ï¼ˆTransformerï¼‰
-        memory = x16_lr.flatten(2).transpose(1, 2)  # [B, 16*16, 256]
-        for enc_layer in self.encoder_layers:
-            memory = enc_layer(memory)  # ä½¿ç”¨ EncoderLayer
-
-        # HR è·¯å¾„ï¼šå…ˆ space_to_depth (block_size=8) -> channels: 1*64 = 64
-        img_HR_patch = self.space_to_depth(img_HR, block_size=8)  # [B,64,32,32]
-        x_hrproc = self.hr_process_convs(img_HR_patch)  # [B,256,32,32]
-
-        # è§£ç å™¨
-        b_hr, c_hr, h_hr, w_hr = x_hrproc.shape
-        x_flat = x_hrproc.flatten(2).transpose(1, 2)  # [B, h_hr*w_hr, c_hr]
-        for dec_layer in self.decoder_layers:
-            x_flat = dec_layer(x_flat, memory)  # ä½¿ç”¨ DecoderLayer
-        x_dec = x_flat.transpose(1, 2).view(b_hr, c_hr, h_hr, w_hr)  # [B,256,32,32]
-
-        # èåˆä¸ä¸Šé‡‡æ ·
-        x_dec_down = F.interpolate(x_dec, size=x16_lr.shape[2:], mode='bilinear', align_corners=False)
-        fea_16 = x_dec_down + x16_lr  # [B,256,16,16] æ³¨æ„ï¼šx_decæ˜¯32->16é”™ä½ï¼Ÿï¼ˆä¸‹æ–‡ alignï¼‰
-        # è¯´æ˜ï¼šåœ¨ä½ çš„åŸä»£ç é‡Œ x_dec çš„ spatial ä¸ x16_lr ä¸€è‡´ï¼Œå› ä¸ºä½ ç”¨çš„ block / reshape æ°å¥½å¯¹é½ã€‚
-        x = self.combine_convs1(fea_16)
-        x = x + fea_16
-        x_hr = self.depth_to_space(x, block_size=2)  # ä¸Šé‡‡æ ·åˆ° 32x32ï¼Œchannels -> 256 // 4 = 64
-
-        fea_32 = x_hr + x32_lr  # 64-ch + 64-ch
-        x = self.combine_convs2(fea_32)  # combine_convs2 ç°åœ¨æ¥å— 64 é€šé“è¾“å…¥
-        x = F.relu(x + fea_32)
-        out = self.depth_to_space(x, block_size=8)  # ä¸Šé‡‡æ ·åˆ° 256x256 (channels -> 64//64 = 1)
-        out = self.final_conv(out)
-        return out
Index: SwinTransCT-main/model.py
===================================================================
diff --git a/SwinTransCT-main/model.py b/SwinTransCT-main/model.py
deleted file mode 100644
--- a/SwinTransCT-main/model.py	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
+++ /dev/null	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
@@ -1,376 +0,0 @@
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-
-
-# --------------------------- é€šç”¨æ¨¡å—å°è£…ï¼ˆå‡å°‘å†—ä½™ï¼Œæå‡å¯ç»´æŠ¤æ€§ï¼‰---------------------------
-class ConvBlock(nn.Module):
-    """é€šç”¨å·ç§¯å—ï¼šConv2d + LeakyReLUï¼Œæ”¯æŒå¯é€‰å¹³å‡æ± åŒ–ï¼ˆå‡å°‘é«˜é¢‘æŸè€—ï¼‰"""
-
-    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, use_pool=False):
-        super().__init__()
-        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
-        self.act = nn.LeakyReLU(inplace=True)
-        self.use_pool = use_pool
-        self.pool = nn.AvgPool2d(2, stride=2)  # å¹³å‡æ± åŒ–æ›¿ä»£å·ç§¯æ­¥é•¿ä¸‹é‡‡æ ·
-
-    def forward(self, x):
-        x = self.act(self.conv(x))
-        if self.use_pool:
-            x = self.pool(x)
-        return x
-
-
-class ResidualConvBlock(nn.Module):
-    """æ®‹å·®å·ç§¯å—ï¼š2ä¸ªConvBlock + æ®‹å·®è¿æ¥ï¼Œå¢å¼ºç‰¹å¾èåˆèƒ½åŠ›"""
-
-    def __init__(self, channels, kernel_size=3, padding=1):
-        super().__init__()
-        # ä¿è¯ä¸¤ä¸ª conv çš„è¾“å…¥è¾“å‡ºé€šé“ä¸€è‡´
-        self.conv1 = ConvBlock(channels, channels, kernel_size, padding=padding)
-        self.conv2 = ConvBlock(channels, channels, kernel_size, padding=padding)
-
-    def forward(self, x):
-        shortcut = x
-        x = self.conv1(x)
-        x = self.conv2(x)
-        return x + shortcut
-
-
-# --------------------------- Swin-Transformer åŸºç¡€æ¨¡å—ï¼ˆä¼˜åŒ–å°ºå¯¸é€‚é…ï¼‰---------------------------
-class WindowAttention(nn.Module):
-    def __init__(self, dim, window_size, num_heads, qkv_bias=True):
-        super().__init__()
-        self.dim = dim
-        self.window_size = window_size  # tuple (H_win, W_win)
-        self.num_heads = num_heads
-        self.head_dim = dim // num_heads
-        self.scale = self.head_dim ** -0.5
-
-        # relative position bias table
-        self.relative_position_bias_table = nn.Parameter(
-            torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads)
-        )
-
-        coords_h = torch.arange(window_size[0])
-        coords_w = torch.arange(window_size[1])
-        coords = torch.stack(torch.meshgrid([coords_h, coords_w], indexing="ij"))  # (2, H_win, W_win)
-        coords_flatten = torch.flatten(coords, 1)  # (2, N)
-        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # (2, N, N)
-        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # (N, N, 2)
-        relative_coords[:, :, 0] += window_size[0] - 1
-        relative_coords[:, :, 1] += window_size[1] - 1
-        relative_coords[:, :, 0] *= 2 * window_size[1] - 1
-        relative_position_index = relative_coords.sum(-1)  # (N, N)
-        self.register_buffer("relative_position_index", relative_position_index)
-
-        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)
-        self.proj = nn.Linear(dim, dim)
-        nn.init.trunc_normal_(self.relative_position_bias_table, std=.02)
-        self.softmax = nn.Softmax(dim=-1)
-
-    def forward(self, x, mask=None):
-        B_, N, C = x.shape
-        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)
-        q, k, v = qkv.unbind(0)
-        q = q * self.scale
-        attn = q @ k.transpose(-2, -1)  # (B_, num_heads, N, N)
-
-        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(
-            self.window_size[0] * self.window_size[1],
-            self.window_size[0] * self.window_size[1],
-            -1
-        ).permute(2, 0, 1).contiguous()  # (num_heads, N, N)
-        attn = attn + relative_position_bias.unsqueeze(0)
-
-        if mask is not None:
-            nW = mask.shape[0]
-            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)
-            attn = attn.view(-1, self.num_heads, N, N)
-        attn = self.softmax(attn)
-        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)
-        x = self.proj(x)
-        return x
-
-
-class SwinBlock(nn.Module):
-    def __init__(self, dim, input_resolution, num_heads, window_size=7, shift_size=0):
-        super().__init__()
-        self.dim = dim
-        self.input_resolution = input_resolution
-        self.num_heads = num_heads
-        self.shift_size = shift_size
-
-        H, W = input_resolution
-        self.window_size = min(window_size, H, W)
-        while H % self.window_size != 0 or W % self.window_size != 0:
-            self.window_size -= 1
-        if min(H, W) <= self.window_size:
-            self.shift_size = 0
-
-        self.norm1 = nn.LayerNorm(dim)
-        self.attn = WindowAttention(dim=dim, window_size=(self.window_size, self.window_size), num_heads=num_heads)
-        self.norm2 = nn.LayerNorm(dim)
-        self.mlp = nn.Sequential(
-            nn.Linear(dim, 4 * dim),
-            nn.GELU(),
-            nn.Linear(4 * dim, dim)
-        )
-
-        if self.shift_size > 0:
-            img_mask = torch.zeros((1, H, W, 1))
-            h_slices = (slice(0, -self.window_size),
-                        slice(-self.window_size, -self.shift_size),
-                        slice(-self.shift_size, None))
-            w_slices = (slice(0, -self.window_size),
-                        slice(-self.window_size, -self.shift_size),
-                        slice(-self.shift_size, None))
-            cnt = 0
-            for h in h_slices:
-                for w in w_slices:
-                    img_mask[:, h, w, :] = cnt
-                    cnt += 1
-            mask_windows = self.window_partition(img_mask)
-            mask_windows = mask_windows.view(-1, self.window_size * self.window_size)
-            attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)
-            attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))
-            self.register_buffer("attn_mask", attn_mask)
-        else:
-            self.attn_mask = None
-
-    def window_partition(self, x):
-        B, H, W, C = x.shape
-        x = x.view(B, H // self.window_size, self.window_size, W // self.window_size, self.window_size, C)
-        windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, self.window_size, self.window_size, C)
-        return windows
-
-    def window_reverse(self, windows, H, W):
-        nW = H // self.window_size * W // self.window_size
-        B = int(windows.shape[0] / nW)
-        x = windows.view(B, H // self.window_size, W // self.window_size, self.window_size, self.window_size, -1)
-        x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)
-        return x
-
-    def forward(self, x):
-        H, W = self.input_resolution
-        B, L, C = x.shape
-        assert L == H * W, f"è¾“å…¥åºåˆ—é•¿åº¦{L}ä¸åˆ†è¾¨ç‡{(H, W)}ä¸åŒ¹é…"
-
-        shortcut = x
-        x = self.norm1(x)
-        x = x.view(B, H, W, C)
-        if self.shift_size > 0:
-            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))
-        else:
-            shifted_x = x
-
-        x_windows = self.window_partition(shifted_x)
-        x_windows = x_windows.view(-1, self.window_size * self.window_size, C)
-        attn_windows = self.attn(x_windows, mask=self.attn_mask)
-        attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)
-        shifted_x = self.window_reverse(attn_windows, H, W)
-        if self.shift_size > 0:
-            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))
-        else:
-            x = shifted_x
-        x = x.view(B, H * W, C)
-        x = x + shortcut
-
-        shortcut = x
-        x = self.norm2(x)
-        x = self.mlp(x)
-        x = x + shortcut
-
-        return x
-
-
-# --------------------------- ä¸»æ¨¡å‹ï¼šLDCTNet_Swinï¼ˆä¼˜åŒ–é«˜é¢‘ä¿ç•™ä¸å‚æ•°é€‚é…ï¼‰---------------------------
-class LDCTNet_Swin(nn.Module):
-
-    def _create_gaussian_kernel(self, kernel_size=11, sigma=1.5):
-        coords = torch.arange(kernel_size, dtype=torch.float32) - (kernel_size - 1) / 2.0
-        x, y = torch.meshgrid(coords, coords, indexing='ij')
-        kernel_2d = torch.exp(-(x ** 2 + y ** 2) / (2 * sigma ** 2))
-        kernel_2d /= kernel_2d.sum()
-
-        # æ‰©å±•ç»´åº¦ä¸º (1,1,k,k)
-        kernel_4d = kernel_2d.unsqueeze(0).unsqueeze(0)
-        return kernel_4d
-
-    def _initialize_weights(self):
-        for m in self.modules():
-            if isinstance(m, nn.Conv2d):
-                nn.init.xavier_normal_(m.weight)
-                if m.bias is not None:
-                    nn.init.constant_(m.bias, 0.0)
-
-    def __init__(self, input_size=(256, 256), base_channels=16, swin_window_size=7, swin_num_heads=8):
-        super(LDCTNet_Swin, self).__init__()
-        self.input_size = input_size
-        self.base_channels = base_channels
-        self.swin_dim = base_channels * 16  # Swinæ¨¡å—è¾“å…¥é€šé“æ•°ï¼ˆ256ï¼‰
-        self.swin_input_res = (16, 16)  # Swinæ¨¡å—è¾“å…¥ç‰¹å¾å›¾å°ºå¯¸ï¼ˆ16x16ï¼‰
-
-        # ä½é¢‘è·¯å¾„ï¼ˆä¸‹é‡‡æ · 4 æ¬¡ï¼š256â†’16ï¼‰
-        self.lr_path = nn.Sequential(
-            ConvBlock(1, base_channels * 1, kernel_size=5, padding=2, use_pool=True),  # 256â†’128
-            ConvBlock(base_channels * 1, base_channels * 2, kernel_size=5, padding=2, use_pool=True),  # 128â†’64
-            ConvBlock(base_channels * 2, base_channels * 4, kernel_size=5, padding=2, use_pool=True),  # 64â†’32
-            ConvBlock(base_channels * 4, self.swin_dim, kernel_size=5, padding=2, use_pool=True)  # 32â†’16
-        )
-
-        # é«˜é¢‘è·¯å¾„ï¼ˆä¿æŒä¸€è‡´ï¼Œæœ€ç»ˆé™é‡‡æ ·è‡³16Ã—16ï¼‰
-        self.hr_conv1 = ConvBlock(1, base_channels * 4, kernel_size=5, padding=2)
-        self.hr_conv2 = ConvBlock(base_channels * 4, base_channels * 8, kernel_size=5, padding=2)
-        self.hr_conv3 = ConvBlock(base_channels * 8, base_channels * 16, kernel_size=5, padding=2)
-        self.hr_conv4 = ConvBlock(base_channels * 16, self.swin_dim, kernel_size=5, padding=2)
-
-        self.hr_pool1 = nn.AvgPool2d(2, stride=2)
-        self.hr_pool2 = nn.AvgPool2d(2, stride=2)
-        self.hr_pool3 = nn.AvgPool2d(2, stride=2)
-        self.hr_pool4 = nn.AvgPool2d(2, stride=2)  # æœ€ç»ˆ 256â†’16
-
-        # SwinTransformer ç¼–ç å™¨å’Œè§£ç å™¨ä¿æŒä¸å˜
-        self.swin_encoder = nn.ModuleList([
-            SwinBlock(self.swin_dim, self.swin_input_res, swin_num_heads, swin_window_size, shift_size=0),
-            SwinBlock(self.swin_dim, self.swin_input_res, swin_num_heads, swin_window_size,
-                      shift_size=swin_window_size // 2),
-            SwinBlock(self.swin_dim, self.swin_input_res, swin_num_heads, swin_window_size, shift_size=0)
-        ])
-
-        self.swin_decoder = nn.ModuleList([
-            SwinBlock(self.swin_dim, self.swin_input_res, swin_num_heads, swin_window_size,
-                      shift_size=swin_window_size // 2),
-            SwinBlock(self.swin_dim, self.swin_input_res, swin_num_heads, swin_window_size, shift_size=0),
-            SwinBlock(self.swin_dim, self.swin_input_res, swin_num_heads, swin_window_size,
-                      shift_size=swin_window_size // 2)
-        ])
-
-        # ç‰¹å¾èåˆä¸ä¸Šé‡‡æ ·æ¨¡å—ï¼ˆä»16Ã—16æ¢å¤åˆ°256Ã—256ï¼‰
-        self.combine_block1 = ResidualConvBlock(channels=self.swin_dim)
-        self.upsample1 = nn.PixelShuffle(2)  # 16â†’32
-        self.combine_block2 = ResidualConvBlock(channels=base_channels * 4)
-        self.upsample2 = nn.PixelShuffle(4)  # 32â†’256
-        self.final_conv = nn.Conv2d(base_channels * 4, 1, kernel_size=3, stride=1, padding=1)
-
-        self._initialize_weights()
-        self.gaussian_kernel = self._create_gaussian_kernel(kernel_size=11, sigma=1.5)
-        self.register_buffer("gaussian_kernel_buf", self.gaussian_kernel, persistent=False)
-
-        # ---------- LR path: æ”¹ä¸º ModuleListï¼Œä¾¿äºæ‹¿åˆ°ä¸­é—´å°ºåº¦ç‰¹å¾ ----------
-        # 512 -> 256 -> 128 -> 64 -> 32
-        self.lr_blocks = nn.ModuleList([
-            ConvBlock(1, base_channels * 1, kernel_size=5, padding=2, use_pool=True),  # -> 256x256, C=16
-            ConvBlock(base_channels * 1, base_channels * 2, kernel_size=5, padding=2, use_pool=True),  # ->128x128, C=32
-            ConvBlock(base_channels * 2, base_channels * 4, kernel_size=5, padding=2, use_pool=True),  # ->64x64, C=64
-            ConvBlock(base_channels * 4, self.swin_dim, kernel_size=5, padding=2, use_pool=True)  # ->32x32, C=256
-        ])
-
-        # ---------- HR path: ä¿®æ”¹ä¸º clear çš„ conv+pool æµç¨‹ ----------
-        self.hr_conv1 = ConvBlock(1, base_channels * 4, kernel_size=5, padding=2)  # (B,64,512,512)
-        self.hr_pool1 = nn.AvgPool2d(2, stride=2)  # ->256
-        self.hr_conv2 = ConvBlock(base_channels * 4, base_channels * 8, kernel_size=5, padding=2)  # (B,128,256,256)
-        self.hr_pool2 = nn.AvgPool2d(2, stride=2)  # ->128
-        self.hr_conv3 = ConvBlock(base_channels * 8, base_channels * 16, kernel_size=5, padding=2)  # (B,256,128,128)
-        self.hr_pool3 = nn.AvgPool2d(2, stride=2)  # ->64
-        self.hr_conv4 = ConvBlock(base_channels * 16, self.swin_dim, kernel_size=5, padding=2)  # (B,256,64,64)
-        self.hr_pool4 = nn.AvgPool2d(2, stride=2)  # ->32
-
-        # ---------- Swin Encoder / Decoder ----------
-        self.swin_encoder = nn.ModuleList([
-            SwinBlock(dim=self.swin_dim, input_resolution=self.swin_input_res, num_heads=swin_num_heads,
-                      window_size=swin_window_size, shift_size=0),
-            SwinBlock(dim=self.swin_dim, input_resolution=self.swin_input_res, num_heads=swin_num_heads,
-                      window_size=swin_window_size, shift_size=swin_window_size // 2),
-            SwinBlock(dim=self.swin_dim, input_resolution=self.swin_input_res, num_heads=swin_num_heads,
-                      window_size=swin_window_size, shift_size=0)
-        ])
-
-        self.swin_decoder = nn.ModuleList([
-            SwinBlock(dim=self.swin_dim, input_resolution=self.swin_input_res, num_heads=swin_num_heads,
-                      window_size=swin_window_size, shift_size=swin_window_size // 2),
-            SwinBlock(dim=self.swin_dim, input_resolution=self.swin_input_res, num_heads=swin_num_heads,
-                      window_size=swin_window_size, shift_size=0),
-            SwinBlock(dim=self.swin_dim, input_resolution=self.swin_input_res, num_heads=swin_num_heads,
-                      window_size=swin_window_size, shift_size=swin_window_size // 2)
-        ])
-
-        # ç‰¹å¾èåˆä¸ä¸Šé‡‡æ ·
-        self.combine_block1 = ResidualConvBlock(channels=self.swin_dim)  # work on 256-ch (32x32)
-        # ç¬¬ä¸€æ¬¡ä¸Šé‡‡æ ·ï¼šPixelShuffle(2) éœ€è¦ in_channels = out_channels * (2^2)
-        # æˆ‘ä»¬çš„ in_channels = 256 -> out_channels = 256/4 = 64, H/W: 32->64
-        self.upsample1 = nn.PixelShuffle(2)
-
-        # combine_block2 operates on 64 channels at 64x64
-        self.combine_block2 = ResidualConvBlock(channels=base_channels * 4)  # channels=64
-
-        # ç¬¬äºŒæ¬¡ä¸Šé‡‡æ ·ï¼šPixelShuffle(8) éœ€è¦ in_channels = out_channels * (8^2)
-        # æˆ‘ä»¬å¸Œæœ›æœ€ç»ˆ out_channels=1 -> in_channels must be 64 (=1*64) -> matches combine_block2 out channels
-        self.upsample2 = nn.PixelShuffle(8)
-
-        # final conv: after upsample2, channels will be 1, æ‰€ä»¥ final_conv è¾“å…¥åº”ä¸º 1
-        self.final_conv = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1)
-
-        self._initialize_weights()
-
-    def forward(self, x):
-        """
-        x: (B,1,H,W) assumed H=W=512
-        returns out: (B,1,H,W)
-        """
-        # 1. é«˜ä½é¢‘åˆ†ç¦»
-        img_LR = F.conv2d(x, self.gaussian_kernel_buf.to(x.device), padding=5)  # (B,1,512,512)
-        img_HR = x - img_LR
-
-        # 2. LR path: é€å±‚è®¡ç®—å¹¶ä¿å­˜ 64x64 çš„ä¸­é—´ç‰¹å¾
-        lr = img_LR
-        lr_feats = []
-        for idx, blk in enumerate(self.lr_blocks):
-            lr = blk(lr)
-            lr_feats.append(
-                lr)  # lr_feats[0]: 256x256 (C=16); lr_feats[1]:128x128(C=32); lr_feats[2]:64x64(C=64); lr_feats[3]:32x32(C=256)
-        x_lr_32 = lr_feats[-1]  # (B,256,32,32)
-        x_lr_64 = lr_feats[-2]  # (B,64,64,64)  <-- ç”¨äºä¸­é—´èåˆ
-
-        # 3. HR path: æ¸…æ™°ä¸”æ­£ç¡®çš„ä¸‹é‡‡æ ·åºåˆ—
-        x_hr = self.hr_conv1(img_HR)  # (B,64,512,512)
-        x_hr = self.hr_pool1(x_hr)  # (B,64,256,256)
-        x_hr = self.hr_conv2(x_hr)  # (B,128,256,256)
-        x_hr = self.hr_pool2(x_hr)  # (B,128,128,128)
-        x_hr = self.hr_conv3(x_hr)  # (B,256,128,128)
-        x_hr = self.hr_pool3(x_hr)  # (B,256,64,64)
-        x_hr = self.hr_conv4(x_hr)  # (B,256,64,64)
-        x_hr = self.hr_pool4(x_hr)  # (B,256,32,32)  final HR feature map to feed Swin decoder
-
-        # 4. Swin Encoder on low-frequency feature x_lr_32 (B,256,32,32)
-        B, C, H, W = x_lr_32.shape
-        x_swin = x_lr_32.flatten(2).transpose(1, 2)  # (B, H*W, C)
-        for blk in self.swin_encoder:
-            x_swin = blk(x_swin)
-        x_swin_enc = x_swin.transpose(1, 2).view(B, C, H, W)  # (B,256,32,32)
-
-        # 5. Swin Decoder: æŠŠ HR ç‰¹å¾ä¸ Encoder è¾“å‡ºèåˆï¼ˆä»¥åºåˆ—å½¢å¼ï¼‰
-        x_swin_hr = x_hr.flatten(2).transpose(1, 2)  # (B, H*W, C)
-        x_swin_enc_seq = x_swin_enc.flatten(2).transpose(1, 2)
-        x_swin = x_swin_hr + x_swin_enc_seq
-        for blk in self.swin_decoder:
-            x_swin = blk(x_swin)
-        x_swin_dec = x_swin.transpose(1, 2).view(B, C, H, W)  # (B,256,32,32)
-
-        # 6. ç‰¹å¾èåˆä¸ä¸Šé‡‡æ ·
-        x_fuse = x_swin_dec + x_lr_32  # (B,256,32,32)
-        x_fuse = self.combine_block1(x_fuse)  # (B,256,32,32)
-
-        # ç¬¬ä¸€æ¬¡ä¸Šé‡‡æ ·ï¼š32x32 -> 64x64, channels 256 -> 64 (PixelShuffle(2))
-        x_up1 = self.upsample1(x_fuse)  # (B,64,64,64)
-
-        # ä¸ lr_path çš„ 64x64 ç‰¹å¾èåˆï¼ˆæ›´åˆç†çš„ skipï¼‰
-        x_fuse2 = x_up1 + x_lr_64  # (B,64,64,64)
-        x_fuse2 = self.combine_block2(x_fuse2)  # (B,64,64,64)
-
-        # ç¬¬äºŒæ¬¡ä¸Šé‡‡æ ·ï¼š16x16 -> 256x256, channels 64 -> 1 (PixelShuffle(8))
-        x_up2 = self.upsample2(x_fuse2)  # (B,1,256,256)
-
-        # æœ€ç»ˆå·ç§¯ï¼šé€šé“ 1 -> 1
-        out = self.final_conv(x_up2)  # (B,1,512,512)
-        return out
Index: SwinTransCT-main/change_Radom.py
===================================================================
diff --git a/SwinTransCT-main/change_Radom.py b/SwinTransCT-main/change_Radom.py
deleted file mode 100644
--- a/SwinTransCT-main/change_Radom.py	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
+++ /dev/null	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
@@ -1,174 +0,0 @@
-import os
-
-import cv2
-import h5py
-import numpy as np
-from tqdm import tqdm  # è¿›åº¦æ¡æ˜¾ç¤º
-
-# --------------------------
-# 1. é…ç½®å‚æ•°ï¼ˆæ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
-# --------------------------
-HDF5_FOLDER = "/Users/lxxxx/Desktop/CODE/SwinCT/ground_truth_test"  # æ›¿æ¢ä¸ºä½ çš„28ä¸ªHDF5æ–‡ä»¶æ‰€åœ¨æ–‡ä»¶å¤¹
-OUTPUT_FOLDER = "/Users/lxxxx/Desktop/CODE/SwinCT/ND_LD_Paired_Data"  # è¾“å‡ºé…å¯¹æ•°æ®çš„æ ¹æ–‡ä»¶å¤¹
-OCCLUSION_RATE = 0.5  # é®æŒ¡ç‡ï¼ˆ0.5=50%å‰‚é‡é™ä½ï¼Œå¯è°ƒæ•´ä¸º0.3/0.7ç­‰ï¼‰
-NOISE_STD = 0.03  # ä½å‰‚é‡å™ªå£°å¼ºåº¦ï¼ˆå‰‚é‡è¶Šä½ï¼Œå™ªå£°è¶Šå¤§ï¼Œå»ºè®®0.02-0.05ï¼‰
-HOLE_SIZE = (5, 5)  # æŒ¡æ¿å­”æ´å¤§å°ï¼ˆåƒç´ ï¼‰ï¼Œæ¨¡æ‹Ÿç‰©ç†æŒ¡æ¿å°ºå¯¸
-CT_WINDOW = (40, 400)  # CTçª—å®½çª—ä½ï¼ˆè½¯ç»„ç»‡çª—ï¼šä¸­å¿ƒ40ï¼Œå®½åº¦400ï¼Œå¯æŒ‰éœ€è°ƒæ•´ï¼‰
-IMAGE_SIZE = (256, 256)  # è¾“å‡ºå›¾åƒå°ºå¯¸ï¼ˆé€‚é…ç¥ç»ç½‘ç»œï¼Œå¯æ”¹ä¸º512/128ç­‰ï¼‰
-
-# åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹ï¼ˆNDå’ŒLDåˆ†å¼€å­˜å‚¨ï¼‰
-nd_output_dir = os.path.join(OUTPUT_FOLDER, "ND")
-ld_output_dir = os.path.join(OUTPUT_FOLDER, "LD")
-os.makedirs(nd_output_dir, exist_ok=True)
-os.makedirs(ld_output_dir, exist_ok=True)
-
-
-# --------------------------
-# 2. å·¥å…·å‡½æ•°ï¼ˆCTçª—å¤„ç†ã€æŒ¡æ¿æ¨¡æ‹Ÿã€æ‰¹é‡è¯»å–ï¼‰
-# --------------------------
-def set_ct_window(img_hu, window_center, window_width):
-    """å½’ä¸€åŒ–æ•°æ®æ— éœ€çª—å¤„ç†ï¼Œç›´æ¥è¿”å›ï¼ˆé¿å…è£å‰ªä¸ºç©ºç™½ï¼‰"""
-    # è‹¥æ•°æ®æ˜¯ 0~1ï¼šç›´æ¥å½’ä¸€åŒ–åˆ°0~1ï¼ˆä¿æŒä¸å˜ï¼‰
-    if img_hu.max() <= 1.0 and img_hu.min() >= 0.0:
-        return np.clip(img_hu, 0.0, 1.0)
-    # è‹¥æ•°æ®æ˜¯ -1~1ï¼šæ˜ å°„åˆ°0~1
-    elif img_hu.max() <= 1.0 and img_hu.min() >= -1.0:
-        return (img_hu + 1.0) / 2.0  # -1â†’0ï¼Œ1â†’1
-    # è‹¥è¿˜æ˜¯HUå€¼ï¼ŒæŒ‰åŸçª—å¤„ç†
-    else:
-        min_val = window_center - window_width / 2
-        max_val = window_center + window_width / 2
-        img_windowed = np.clip(img_hu, min_val, max_val)
-        img_windowed = (img_windowed - min_val) / (max_val - min_val)
-        return img_windowed
-
-
-def generate_random_mask(height, width, occlusion_rate, hole_size):
-    """ç”ŸæˆéšæœºæŒ¡æ¿æ¨¡æ¿ï¼ˆé€‚é…å•å¼ å›¾åƒå°ºå¯¸ï¼‰"""
-    # åŸºç¡€éšæœºäºŒè¿›åˆ¶æ¨¡æ¿ï¼ˆ0=é®æŒ¡ï¼Œ1=é€šé€ï¼‰
-    np.random.seed(None)  # ä¸å›ºå®šç§å­ï¼Œæ¯å¼ å›¾æŒ¡æ¿åˆ†å¸ƒä¸åŒï¼ˆå¢å¼ºæ³›åŒ–æ€§ï¼‰
-    mask = np.random.choice([0, 1], size=(height, width), p=[occlusion_rate, 1 - occlusion_rate])
-    mask = mask.astype(np.uint8)
-    # å½¢æ€å­¦å¤„ç†ï¼šå¹³æ»‘å­”æ´ï¼Œæ¨¡æ‹ŸçœŸå®æŒ¡æ¿
-    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, hole_size)
-    mask = cv2.dilate(mask, kernel)
-    mask = cv2.erode(mask, kernel)
-    return mask.astype(np.float32)
-
-
-def simulate_low_dose_ct(nd_img_hu, mask, noise_std):
-    """å°†æ ‡å‡†å‰‚é‡CTï¼ˆHUå€¼ï¼‰æ¨¡æ‹Ÿä¸ºä½å‰‚é‡CTï¼ˆæŒ¡æ¿+å™ªå£°ï¼‰"""
-    # æ­¥éª¤1ï¼šCTçª—å¤„ç†ï¼ˆè½¬ä¸º0-1çš„ç°åº¦å›¾ï¼‰
-    nd_img_norm = set_ct_window(nd_img_hu, *CT_WINDOW)
-    # æ­¥éª¤2ï¼šæŒ¡æ¿é®æŒ¡ï¼ˆæ¨¡æ‹Ÿç¨€ç–ä¿¡å·ï¼‰
-    sparse_img = nd_img_norm * mask
-    # æ­¥éª¤3ï¼šæ·»åŠ ä½å‰‚é‡ç»Ÿè®¡å™ªå£°
-    noise = np.random.normal(0, noise_std, size=nd_img_norm.shape)
-    ld_img_norm = sparse_img + noise
-    # æ­¥éª¤4ï¼šè£å‰ªæº¢å‡ºå€¼ï¼Œç¡®ä¿0-1èŒƒå›´
-    ld_img_norm = np.clip(ld_img_norm, 0.0, 1.0)
-    # æ­¥éª¤5ï¼šè½»å¾®å¹³æ»‘ï¼ˆæ¨¡æ‹Ÿä½å‰‚é‡CTçš„å™ªå£°ç‰¹æ€§ï¼Œå¯é€‰ï¼‰
-    ld_img_norm = cv2.GaussianBlur(ld_img_norm, (3, 3), sigmaX=0.8)
-    return nd_img_norm, ld_img_norm
-
-
-def read_hdf5_ct_images(hdf5_path):
-    """è¯»å–å•ä¸ªHDF5æ–‡ä»¶ä¸­çš„æ‰€æœ‰128å¼ NDCTå›¾åƒï¼ˆHUå€¼ï¼‰"""
-    ct_images_hu = []
-    with h5py.File(hdf5_path, "r") as f:
-        # --------------------------
-        # å…³é”®ï¼šæ ¹æ®ä½ çš„HDF5ç»“æ„ä¿®æ”¹è·¯å¾„ï¼
-        # å‡è®¾CTå›¾åƒï¼ˆHUå€¼ï¼‰å­˜å‚¨åœ¨ "/reconstructed_images" æˆ– "/ct_images" è·¯å¾„ä¸‹
-        # è‹¥ä¸ç¡®å®šï¼Œå…ˆè¿è¡Œä¹‹å‰çš„HDF5ç»“æ„éå†ä»£ç ç¡®è®¤ï¼
-        # --------------------------
-        # ç¤ºä¾‹1ï¼šå¦‚æœå›¾åƒå­˜å‚¨åœ¨åˆ†ç»„ä¸‹çš„æ•°æ®é›†ï¼ˆå¸¸è§ç§‘ç ”ç»“æ„ï¼‰
-        if "/data" in f:
-            img_dataset = f["/data"]
-        elif "/ct_images" in f:
-            img_dataset = f["/ct_images"]
-        elif "/images" in f:
-            img_dataset = f["/images"]
-        else:
-            raise ValueError(f"HDF5æ–‡ä»¶ {hdf5_path} ä¸­æœªæ‰¾åˆ°CTå›¾åƒæ•°æ®é›†ï¼è¯·ç¡®è®¤è·¯å¾„ã€‚")
-
-        # è¯»å–æ‰€æœ‰å›¾åƒï¼ˆå‡è®¾æ•°æ®é›†å½¢çŠ¶ä¸º (128, H, W) â†’ (æ•°é‡, é«˜åº¦, å®½åº¦)ï¼‰
-        if img_dataset.shape[0] == 128:
-            ct_images_hu = img_dataset[:]  # (128, H, W)
-        else:
-            # è‹¥å½¢çŠ¶ä¸º (H, W, 128)ï¼Œè½¬ç½®ä¸º (128, H, W)
-            ct_images_hu = np.transpose(img_dataset, (2, 0, 1))
-
-        # æ–°å¢ï¼šæ‰“å°æ•°æ®çš„æ•°å€¼èŒƒå›´ï¼ˆå…³é”®ï¼ï¼‰
-        print(f"\n{os.path.basename(hdf5_path)} æ•°æ®èŒƒå›´ï¼š")
-        print(f"æœ€å°å€¼ï¼š{ct_images_hu.min():.2f} | æœ€å¤§å€¼ï¼š{ct_images_hu.max():.2f}")
-        print(f"å¹³å‡å€¼ï¼š{ct_images_hu.mean():.2f}")
-
-        # ç¡®ä¿æ•°æ®æ˜¯HUå€¼ï¼ˆè‹¥HDF5å­˜å‚¨çš„æ˜¯å½’ä¸€åŒ–åçš„æ•°æ®ï¼Œéœ€æ³¨é‡Šä»¥ä¸‹æ ¡å‡†æ­¥éª¤ï¼‰
-        # å‡è®¾HDF5ä¸­å­˜å‚¨äº†æ ¡å‡†å‚æ•°ï¼ˆæ–œç‡/æˆªè·ï¼‰ï¼Œè‹¥æ²¡æœ‰åˆ™æ‰‹åŠ¨è®¾ç½®ï¼ˆå¦‚ slope=1, intercept=-1024ï¼‰
-        if "rescale_slope" in img_dataset.attrs and "rescale_intercept" in img_dataset.attrs:
-            slope = img_dataset.attrs["rescale_slope"]
-            intercept = img_dataset.attrs["rescale_intercept"]
-            ct_images_hu = ct_images_hu * slope + intercept  # è½¬æ¢ä¸ºHUå€¼
-
-    return ct_images_hu
-
-
-# --------------------------
-# 3. æ‰¹é‡å¤„ç†ä¸»æµç¨‹
-# --------------------------
-def batch_process_hdf5_to_paired_nd_ld():
-    # è·å–æ‰€æœ‰HDF5æ–‡ä»¶ï¼ˆæŒ‰æ–‡ä»¶åæ’åºï¼Œç¡®ä¿é¡ºåºä¸€è‡´ï¼‰
-    hdf5_files = [f for f in os.listdir(HDF5_FOLDER) if f.endswith(".h5") or f.endswith(".hdf5")]
-    hdf5_files.sort()  # æ’åºï¼Œé¿å…å¤„ç†é¡ºåºæ··ä¹±
-    print(f"æ‰¾åˆ° {len(hdf5_files)} ä¸ªHDF5æ–‡ä»¶ï¼Œå¼€å§‹æ‰¹é‡å¤„ç†...")
-
-    total_img_count = 0  # ç»Ÿè®¡æ€»å›¾åƒæ•°ï¼ˆ28Ã—128=3584å¼ ï¼‰
-
-    # éå†æ¯ä¸ªHDF5æ–‡ä»¶
-    for hdf5_idx, hdf5_file in enumerate(hdf5_files):
-        hdf5_path = os.path.join(HDF5_FOLDER, hdf5_file)
-        print(f"\nå¤„ç†ç¬¬ {hdf5_idx + 1}/{len(hdf5_files)} ä¸ªæ–‡ä»¶ï¼š{hdf5_file}")
-
-        # è¯»å–å½“å‰HDF5ä¸­çš„128å¼ CTå›¾åƒï¼ˆHUå€¼ï¼‰
-        try:
-            ct_images_hu = read_hdf5_ct_images(hdf5_path)
-            assert len(ct_images_hu) == 128, f"è¯¥HDF5æ–‡ä»¶ä»…åŒ…å« {len(ct_images_hu)} å¼ å›¾åƒï¼Œä¸ç¬¦åˆ128å¼ è¦æ±‚ï¼"
-        except Exception as e:
-            print(f"è­¦å‘Šï¼šè¯»å– {hdf5_file} å¤±è´¥ï¼é”™è¯¯ï¼š{str(e)}ï¼Œè·³è¿‡è¯¥æ–‡ä»¶ã€‚")
-            continue
-
-        # éå†å½“å‰HDF5ä¸­çš„æ¯å¼ å›¾åƒ
-        for img_idx, img_hu in tqdm(enumerate(ct_images_hu), total=128, desc="å¤„ç†å›¾åƒ"):
-            # ç”Ÿæˆå½“å‰å›¾åƒçš„ä¸“å±éšæœºæŒ¡æ¿æ¨¡æ¿ï¼ˆæ¯å¼ å›¾æŒ¡æ¿ä¸åŒï¼‰
-            mask = generate_random_mask(img_hu.shape[0], img_hu.shape[1], OCCLUSION_RATE, HOLE_SIZE)
-
-            # æ¨¡æ‹Ÿä½å‰‚é‡CT
-            nd_img_norm, ld_img_norm = simulate_low_dose_ct(img_hu, mask, NOISE_STD)
-
-            # è°ƒæ•´å›¾åƒå°ºå¯¸ï¼ˆé€‚é…ç¥ç»ç½‘ç»œï¼‰
-            nd_img_resized = cv2.resize(nd_img_norm, IMAGE_SIZE)
-            ld_img_resized = cv2.resize(ld_img_norm, IMAGE_SIZE)
-
-            # ç”Ÿæˆé…å¯¹æ–‡ä»¶åï¼ˆæ ¼å¼ï¼šnd_0001.png, ld_0001.pngï¼ŒæŒ‰æ€»è®¡æ•°æ’åºï¼‰
-            total_img_count += 1
-            img_filename = f"{total_img_count:04d}.png"  # 4ä½æ•°å­—ç¼–å·ï¼ˆ0001~3584ï¼‰
-            nd_save_path = os.path.join(nd_output_dir, img_filename)
-            ld_save_path = os.path.join(ld_output_dir, img_filename)
-
-            # è½¬æ¢ä¸º8ä½ç°åº¦å›¾ï¼ˆ0-255ï¼‰å¹¶ä¿å­˜
-            nd_img_uint8 = (nd_img_resized * 255).astype(np.uint8)
-            ld_img_uint8 = (ld_img_resized * 255).astype(np.uint8)
-            cv2.imwrite(nd_save_path, nd_img_uint8)
-            cv2.imwrite(ld_save_path, ld_img_uint8)
-
-    print(f"\næ‰¹é‡å¤„ç†å®Œæˆï¼")
-    print(f"æ€»ç”Ÿæˆé…å¯¹å›¾åƒæ•°ï¼š{total_img_count} å¯¹ï¼ˆNDå’ŒLDå„ {total_img_count} å¼ ï¼‰")
-    print(f"NDå›¾åƒè·¯å¾„ï¼š{nd_output_dir}")
-    print(f"LDå›¾åƒè·¯å¾„ï¼š{ld_output_dir}")
-
-
-# --------------------------
-# 4. æ‰§è¡Œæ‰¹é‡å¤„ç†
-# --------------------------
-if __name__ == "__main__":
-    batch_process_hdf5_to_paired_nd_ld()
Index: SwinTransCT-main/model_improve.py
===================================================================
diff --git a/SwinTransCT-main/model_improve.py b/SwinTransCT-main/model_improve.py
deleted file mode 100644
--- a/SwinTransCT-main/model_improve.py	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
+++ /dev/null	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
@@ -1,206 +0,0 @@
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-
-
-# ======================
-# ConvBlock å¢åŠ  InstanceNorm2d
-# ======================
-class ConvBlock(nn.Module):
-    def __init__(self, in_ch, out_ch, pool=False):
-        super().__init__()
-        self.pool = pool
-        self.conv = nn.Sequential(
-            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),
-            nn.InstanceNorm2d(out_ch),  # âœ… åŠ å…¥ InstanceNorm
-            nn.LeakyReLU(0.2, inplace=True)
-        )
-        if pool:
-            self.avgpool = nn.AvgPool2d(2, 2)
-
-    def forward(self, x):
-        x = self.conv(x)
-        if self.pool:
-            x = self.avgpool(x)
-        return x
-
-
-# ======================
-# ResidualConvBlock åŒæ ·åŠ å…¥ InstanceNorm
-# ======================
-class ResidualConvBlock(nn.Module):
-    def __init__(self, channels):
-        super().__init__()
-        self.block = nn.Sequential(
-            nn.Conv2d(channels, channels, kernel_size=3, padding=1),
-            nn.InstanceNorm2d(channels),
-            nn.LeakyReLU(0.2, inplace=True),
-            nn.Conv2d(channels, channels, kernel_size=3, padding=1),
-            nn.InstanceNorm2d(channels)
-        )
-
-    def forward(self, x):
-        return x + self.block(x)
-
-
-# ======================
-# å¯å­¦ä¹ é«˜æ–¯å·ç§¯æ¨¡å— (æ›¿ä»£å›ºå®šé«˜æ–¯æ ¸)
-# ======================
-class LearnableGaussianBlur(nn.Module):
-    """å¯å­¦ä¹ çš„é«˜æ–¯æ»¤æ³¢å™¨ï¼Œç”¨Conv2då®ç°å¹¶åˆå§‹åŒ–ä¸ºé«˜æ–¯æƒé‡"""
-
-    def __init__(self, channels=1, kernel_size=5, sigma=1.5):
-        super().__init__()
-        self.kernel_size = kernel_size
-        self.sigma = sigma
-
-        self.conv = nn.Conv2d(
-            in_channels=channels,
-            out_channels=channels,
-            kernel_size=kernel_size,
-            padding=kernel_size // 2,
-            groups=channels,  # depthwise
-            bias=False
-        )
-        self._init_gaussian_weights()
-
-    def _init_gaussian_weights(self):
-        """åˆå§‹åŒ–ä¸ºå›ºå®šé«˜æ–¯æ ¸"""
-        k = self.kernel_size
-        sigma = self.sigma
-        coords = torch.arange(k) - k // 2
-        x_grid, y_grid = torch.meshgrid(coords, coords, indexing="xy")
-        g = torch.exp(-(x_grid ** 2 + y_grid ** 2) / (2 * sigma ** 2))
-        g = g / g.sum()
-        weight = g.view(1, 1, k, k).repeat(self.conv.out_channels, 1, 1, 1)
-        with torch.no_grad():
-            self.conv.weight.copy_(weight)
-
-    def forward(self, x):
-        return self.conv(x)
-
-
-# ======================
-# Swin Attention Blockï¼ˆç•¥ï¼Œä¿æŒåŸå®ç°ï¼‰
-# ======================
-class WindowAttention(nn.Module):
-    def __init__(self, dim, window_size=4, num_heads=4):
-        super().__init__()
-        self.num_heads = num_heads
-        self.scale = (dim // num_heads) ** -0.5
-        self.qkv = nn.Linear(dim, dim * 3)
-        self.proj = nn.Linear(dim, dim)
-        self.window_size = window_size
-
-    def forward(self, x):
-        B, N, C = x.shape
-        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads)
-        q, k, v = qkv[:, :, 0], qkv[:, :, 1], qkv[:, :, 2]
-        attn = (q @ k.transpose(-2, -1)) * self.scale
-        attn = attn.softmax(dim=-1)
-        x = (attn @ v).transpose(1, 2).reshape(B, N, C)
-        x = self.proj(x)
-        return x
-
-
-# SwinBlock åŒæ ·ä¿æŒåŸæœ‰åŠŸèƒ½
-class SwinBlock(nn.Module):
-    def __init__(self, dim, num_heads, window_size=4):
-        super().__init__()
-        self.attn = WindowAttention(dim, window_size, num_heads)
-        self.norm1 = nn.LayerNorm(dim)
-        self.mlp = nn.Sequential(
-            nn.Linear(dim, dim * 4),
-            nn.GELU(),
-            nn.Linear(dim * 4, dim)
-        )
-        self.norm2 = nn.LayerNorm(dim)
-
-    def forward(self, x):
-        x = x + self.attn(self.norm1(x))
-        x = x + self.mlp(self.norm2(x))
-        return x
-
-
-# ======================
-# ä¸»ç½‘ç»œç»“æ„ (LDCTNet_Swin)
-# ======================
-class LDCTNet_Swin_improve(nn.Module):
-    def __init__(self):
-        super().__init__()
-
-        # --- å¯å­¦ä¹ é«˜æ–¯æ ¸ ---
-        self.gaussian = LearnableGaussianBlur(channels=1, kernel_size=5, sigma=1.5)
-
-        # --- é«˜é¢‘ä¸ä½é¢‘è·¯å¾„ ---
-        self.conv_hr1 = ConvBlock(1, 64, pool=True)
-        self.conv_hr2 = ConvBlock(64, 128, pool=True)
-        self.conv_hr3 = ConvBlock(128, 256, pool=True)
-        self.conv_hr4 = ConvBlock(256, 256, pool=True)
-
-        self.conv_lr1 = ConvBlock(1, 64, pool=True)
-        self.conv_lr2 = ConvBlock(64, 128, pool=True)
-        self.conv_lr3 = ConvBlock(128, 256, pool=True)
-        self.conv_lr4 = ConvBlock(256, 256, pool=True)
-
-        # --- Swin Transformer ä¸»å¹² ---
-        self.swin_enc1 = SwinBlock(256, num_heads=4, window_size=4)
-        self.swin_enc2 = SwinBlock(256, num_heads=4, window_size=4)
-        self.swin_enc3 = SwinBlock(256, num_heads=4, window_size=4)
-
-        self.swin_dec1 = SwinBlock(256, num_heads=4, window_size=4)
-        self.swin_dec2 = SwinBlock(256, num_heads=4, window_size=4)
-        self.swin_dec3 = SwinBlock(256, num_heads=4, window_size=4)
-
-        # --- èåˆä¸ä¸Šé‡‡æ · ---
-        self.res_fuse = ResidualConvBlock(256)
-        self.upsample1 = nn.Sequential(
-            nn.PixelShuffle(2),
-            nn.Conv2d(64, 64, 3, 1, 1),
-            nn.LeakyReLU(inplace=True)
-        )
-        self.upsample2 = nn.Sequential(
-            nn.PixelShuffle(2),
-            nn.Conv2d(16, 16, 3, 1, 1),
-            nn.LeakyReLU(inplace=True)
-        )
-        self.upsample3 = nn.Sequential(
-            nn.PixelShuffle(2),
-            nn.Conv2d(4, 4, 3, 1, 1),
-            nn.LeakyReLU(inplace=True)
-        )
-
-        self.final_conv = nn.Conv2d(4, 1, 3, 1, 1)
-        self.out_act = nn.Sigmoid()
-
-    def forward(self, x):
-        # ------------------- é«˜ä½é¢‘åˆ†ç¦» -------------------
-        x_low = self.gaussian(x)  # ä½é¢‘
-        x_high = x - x_low  # é«˜é¢‘
-
-        # ------------------- HR/LR ç‰¹å¾æå– -------------------
-        x_hr = self.conv_hr4(self.conv_hr3(self.conv_hr2(self.conv_hr1(x_high))))
-        x_lr = self.conv_lr4(self.conv_lr3(self.conv_lr2(self.conv_lr1(x_low))))
-
-        # ------------------- Swin Transformer ç¼–ç è§£ç  -------------------
-        B, C, H, W = x_lr.shape
-        x_flat = x_lr.flatten(2).transpose(1, 2)  # (B, N, C)
-        x_enc = self.swin_enc3(self.swin_enc2(self.swin_enc1(x_flat)))
-        x_dec = self.swin_dec3(self.swin_dec2(self.swin_dec1(x_enc)))
-        x_dec = x_dec.transpose(1, 2).reshape(B, C, H, W)
-
-        # ------------------- èåˆ -------------------
-        fea_fused = self.res_fuse(x_dec + x_hr)
-
-        # ------------------- ä¸Šé‡‡æ · PixelShuffle 3 æ¬¡ -------------------
-        # fea_fused å‡è®¾ [B,256,16,16]
-        x = self.upsample1(fea_fused)  # -> [B,64,32,32]
-        x = self.upsample2(x)  # -> [B,16,64,64]
-        x = self.upsample3(x)  # -> [B,4,128,128]
-
-        # ------------------- æœ€ç»ˆè¾“å‡ºåˆ°256x256 -------------------
-        x = F.interpolate(x, size=(256, 256), mode='bilinear', align_corners=False)
-        x = self.final_conv(x)  # -> [B,1,256,256]
-
-        # ------------------- è¾“å‡ºæ¿€æ´» -------------------
-        return self.out_act(x)
Index: SwinTransCT-main/loss.py
===================================================================
diff --git a/SwinTransCT-main/loss.py b/SwinTransCT-main/loss.py
deleted file mode 100644
--- a/SwinTransCT-main/loss.py	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
+++ /dev/null	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
@@ -1,68 +0,0 @@
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-
-
-class HybridLoss(nn.Module):
-    """
-    Hybrid Loss for CT reconstruction:
-    L = 0.7*L1 + 0.2*(1-SSIM) + 0.1*EdgeLoss
-    è¾“å…¥è¾“å‡ºå°ºå¯¸: [B, 1, H, W]
-    """
-
-    def __init__(self, alpha=0.7, beta=0.2, gamma=0.1,
-                 window_size=11, window_sigma=1.5, device='cuda'):
-        super(HybridLoss, self).__init__()
-        self.alpha = alpha
-        self.beta = beta
-        self.gamma = gamma
-        self.window_size = window_size
-        self.device = device
-
-        # é«˜æ–¯å·ç§¯æ ¸ï¼Œç”¨äº SSIM
-        self.gaussian_kernel = self.create_gaussian_kernel(window_size, window_sigma).to(device)
-
-        # Sobel å·ç§¯æ ¸ï¼Œç”¨äº Edge Loss
-        self.sobel_x = torch.tensor([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=torch.float32, device=device).view(1, 1,
-                                                                                                                   3, 3)
-        self.sobel_y = torch.tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=torch.float32, device=device).view(1, 1,
-                                                                                                                   3, 3)
-
-    def create_gaussian_kernel(self, size, sigma):
-        coords = torch.arange(size, dtype=torch.float32) - size // 2
-        g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
-        g = g / g.sum()
-        kernel_2d = g[:, None] @ g[None, :]  # å¤–ç§¯å¾—åˆ° 2D
-        kernel_2d = kernel_2d.unsqueeze(0).unsqueeze(0)  # [1,1,H,W]
-        return kernel_2d
-
-    def ssim(self, img1, img2, C1=1e-4, C2=9e-4):
-        """è®¡ç®— SSIMï¼Œè¾“å…¥ [B,1,H,W]"""
-        mu1 = F.conv2d(img1, self.gaussian_kernel, padding=self.window_size // 2)
-        mu2 = F.conv2d(img2, self.gaussian_kernel, padding=self.window_size // 2)
-        mu1_sq = mu1 ** 2
-        mu2_sq = mu2 ** 2
-        mu1_mu2 = mu1 * mu2
-
-        sigma1_sq = F.conv2d(img1 * img1, self.gaussian_kernel, padding=self.window_size // 2) - mu1_sq
-        sigma2_sq = F.conv2d(img2 * img2, self.gaussian_kernel, padding=self.window_size // 2) - mu2_sq
-        sigma12 = F.conv2d(img1 * img2, self.gaussian_kernel, padding=self.window_size // 2) - mu1_mu2
-
-        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))
-        return ssim_map.mean()
-
-    def edge_loss(self, pred, target):
-        """åŸºäº Sobel è¾¹ç¼˜çš„ L1 æŸå¤±"""
-        gx_pred = F.conv2d(pred, self.sobel_x, padding=1)
-        gy_pred = F.conv2d(pred, self.sobel_y, padding=1)
-        gx_target = F.conv2d(target, self.sobel_x, padding=1)
-        gy_target = F.conv2d(target, self.sobel_y, padding=1)
-        loss = F.l1_loss(gx_pred, gx_target) + F.l1_loss(gy_pred, gy_target)
-        return loss
-
-    def forward(self, pred, target):
-        l1 = F.l1_loss(pred, target)
-        ssim_loss = 1 - self.ssim(pred, target)
-        edge = self.edge_loss(pred, target)
-        loss = self.alpha * l1 + self.beta * ssim_loss + self.gamma * edge
-        return loss
Index: SwinTransCT-main/train.py
===================================================================
diff --git a/SwinTransCT-main/train.py b/SwinTransCT-main/train.py
deleted file mode 100644
--- a/SwinTransCT-main/train.py	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
+++ /dev/null	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
@@ -1,458 +0,0 @@
-import argparse
-import os
-import random
-
-import numpy as np
-import torch
-import torch.optim as optim
-from torch.utils.data import DataLoader
-from torch.utils.tensorboard import SummaryWriter
-from tqdm import tqdm
-
-from Trans_model import LDCTNet256  # ä½ çš„LDCTNet_Swinæ¨¡å‹
-from dataset import CTDataset, get_pair_list  # æˆ‘çš„æ•°æ®é›†ç±»
-# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—ï¼ˆç¡®ä¿è·¯å¾„æ­£ç¡®ï¼Œè‹¥æŠ¥é”™éœ€è°ƒæ•´å¯¼å…¥è·¯å¾„ï¼‰
-from loss import HybridLoss
-from utils import ImageMetrics  # æŒ‡æ ‡è®¡ç®—æ¨¡å—ï¼ˆPSNR/SSIM/RMSEï¼‰
-from utils import TrainingRecorder  # æŒ‡æ ‡è®¡ç®—æ¨¡å—ï¼ˆPSNR/SSIM/RMSEï¼‰
-
-torch.manual_seed(0)
-np.random.seed(0)
-random.seed(0)
-
-
-def save_image_grid(ld_img, nd_img, output_img, save_path, epoch):
-    """
-    ä¿å­˜ä¸€è¡Œ3åˆ—çš„å›¾åƒå¯¹æ¯”å›¾ï¼ˆä»…å–ç¬¬ä¸€ä¸ªæ ·æœ¬ï¼Œé¿å…å¤šæ ·æœ¬å¹²æ‰°ï¼‰
-    å¸ƒå±€ï¼šä½å‰‚é‡è¾“å…¥ â†’ æ­£å¸¸å‰‚é‡æ ‡ç­¾ â†’ æ¨¡å‹è¾“å‡º
-    Args:
-        ld_img: ä½å‰‚é‡CTè¾“å…¥ [B,1,H,W]
-        nd_img: æ­£å¸¸å‰‚é‡CTæ ‡ç­¾ [B,1,H,W]
-        output_img: æ¨¡å‹è¾“å‡º [B,1,H,W]
-        save_path: å›¾åƒä¿å­˜ç›®å½•
-        epoch: å½“å‰epochç¼–å·
-    """
-    # åˆ›å»ºä¿å­˜ç›®å½•
-    os.makedirs(save_path, exist_ok=True)
-
-    # å›¾åƒå½’ä¸€åŒ–åˆ°[0,1]ï¼ˆæŒ‰å•ä¸ªæ ·æœ¬å½’ä¸€åŒ–ï¼Œä¿è¯äº®åº¦å‡è¡¡ï¼‰
-    def normalize(img):
-        img = img.detach().cpu()
-        img_min = img.min()
-        img_max = img.max()
-        return (img - img_min) / (img_max - img_min + 1e-8)  # é¿å…é™¤é›¶
-
-    # åªå–ç¬¬ä¸€ä¸ªæ ·æœ¬ï¼ˆ[B,1,H,W] â†’ [1,H,W]ï¼‰ï¼Œé¿å…å¤šæ ·æœ¬æ··ä¹±
-    ld_sample = ld_img[0:1]  # å–ç¬¬ä¸€ä¸ªæ ·æœ¬ï¼Œä¿æŒ[1,1,H,W]æ ¼å¼
-    nd_sample = nd_img[0:1]
-    output_sample = output_img[0:1]
-
-    # å½’ä¸€åŒ–
-    ld_norm = normalize(ld_sample)
-    nd_norm = normalize(nd_sample)
-    output_norm = normalize(output_sample)
-
-    # æ‹¼æ¥ä¸ºä¸€è¡Œ3åˆ—ï¼šä½å‰‚é‡ï¼ˆå·¦ï¼‰â†’ æ­£å¸¸å‰‚é‡ï¼ˆä¸­ï¼‰â†’ æ¨¡å‹è¾“å‡ºï¼ˆå³ï¼‰
-    # æŒ‰æ°´å¹³æ–¹å‘ï¼ˆdim=3ï¼‰æ‹¼æ¥ï¼Œæœ€ç»ˆå½¢çŠ¶ï¼š[1,1,H, 3*W]
-    comparison_img = torch.cat([ld_norm, nd_norm, output_norm], dim=3)
-
-    # è½¬æ¢ä¸ºPILå›¾åƒï¼ˆé€‚é…ä¿å­˜ï¼‰
-    from PIL import Image
-    # å¤„ç†ç»´åº¦ï¼š[1,1,H,3W] â†’ [H,3W]ï¼ˆå»æ‰æ‰¹é‡å’Œé€šé“ç»´åº¦ï¼‰
-    img_np = comparison_img.squeeze(0).squeeze(0).numpy()
-    img_np = (img_np * 255).astype(np.uint8)  # [0,1] â†’ [0,255]
-
-    # ä¿å­˜æ–‡ä»¶ï¼ˆæ–‡ä»¶åå«epochï¼Œä¾¿äºæŒ‰é¡ºåºæŸ¥çœ‹ï¼‰
-    save_filename = f"epoch_{epoch:03d}_comparison.png"  # 03dè¡¥é›¶ï¼ˆå¦‚005ã€010ï¼‰
-    save_filepath = os.path.join(save_path, save_filename)
-    Image.fromarray(img_np, mode='L').save(save_filepath)  # mode='L'ï¼šç°åº¦å›¾æ ¼å¼
-
-    # æ‰“å°ä¿å­˜æ—¥å¿—
-    print(f"[å›¾åƒä¿å­˜] ä¸€è¡Œä¸‰åˆ—å¯¹æ¯”å›¾å·²ä¿å­˜ï¼š{save_filepath}")
-    print(f"[å›¾åƒå¸ƒå±€] å·¦ï¼šä½å‰‚é‡è¾“å…¥ | ä¸­ï¼šæ­£å¸¸å‰‚é‡æ ‡ç­¾ | å³ï¼šæ¨¡å‹è¾“å‡º")
-
-
-def train_one_epoch(model, train_loader, criterion, optimizer, metrics_fn, device, epoch, writer):
-    """è®­ç»ƒä¸€ä¸ªepochï¼ŒåŒæ­¥è®¡ç®—æŸå¤±å’Œå›¾åƒè´¨é‡æŒ‡æ ‡"""
-    model.train()
-    # åˆå§‹åŒ–ç´¯è®¡å˜é‡ï¼ˆæŒ‰æ ·æœ¬æ•°åŠ æƒï¼‰
-    total_loss = 0.0
-    total_psnr = 0.0
-    total_ssim = 0.0
-    total_rmse = 0.0
-    total_samples = 0
-
-    # è¿›åº¦æ¡æ˜¾ç¤ºè®­ç»ƒè¿‡ç¨‹
-    progress_bar = tqdm(train_loader, desc=f"[Train] Epoch {epoch:3d}", unit="batch")
-    for batch_idx, (ld_img, nd_img) in enumerate(progress_bar):
-        # æ•°æ®ç§»è‡³è®¾å¤‡ï¼ˆCPU/GPUï¼‰
-        ld_img = ld_img.to(device, non_blocking=True)  # ä½å‰‚é‡CTï¼ˆè¾“å…¥ï¼‰
-        nd_img = nd_img.to(device, non_blocking=True)  # æ­£å¸¸å‰‚é‡CTï¼ˆæ ‡ç­¾ï¼‰
-        batch_size = ld_img.size(0)
-        total_samples += batch_size
-
-        # 1. æ¸…é›¶æ¢¯åº¦
-        optimizer.zero_grad()
-
-        # 2. å‰å‘ä¼ æ’­
-        outputs = model(ld_img)
-
-        # 3. è®¡ç®—æŸå¤±å’ŒæŒ‡æ ‡
-        loss = criterion(outputs, nd_img)
-        metrics = metrics_fn(outputs, nd_img)  # ä¸€æ¬¡æ€§è·å–PSNR/SSIM/RMSE
-
-        # 4. åå‘ä¼ æ’­ä¸å‚æ•°æ›´æ–°
-        loss.backward()
-        optimizer.step()  # æ›´æ–°æƒé‡
-
-        # 5. ç´¯è®¡æŸå¤±å’ŒæŒ‡æ ‡
-        total_loss += loss.item() * batch_size
-        total_psnr += metrics["psnr"] * batch_size
-        total_ssim += metrics["ssim"] * batch_size
-        total_rmse += metrics["rmse"] * batch_size
-
-        # 6. å®æ—¶æ›´æ–°è¿›åº¦æ¡ï¼ˆæ˜¾ç¤ºå½“å‰batchçš„æŸå¤±å’ŒPSNRï¼‰
-        progress_bar.set_postfix({
-            "batch_loss": f"{loss.item():.6f}",
-            "batch_psnr": f"{metrics['psnr']:.2f}",
-            "batch_ssim": f"{metrics['ssim']:.4f}"
-        })
-
-        # 7. è®°å½•batchçº§æ—¥å¿—ï¼ˆæ¯10ä¸ªbatchå†™ä¸€æ¬¡TensorBoardï¼‰
-        if (batch_idx + 1) % 10 == 0:
-            global_step = epoch * len(train_loader) + batch_idx
-            writer.add_scalar("Train/Batch_Loss", loss.item(), global_step)
-            writer.add_scalar("Train/Batch_PSNR", metrics["psnr"], global_step)
-            writer.add_scalar("Train/Batch_SSIM", metrics["ssim"], global_step)
-            writer.add_scalar("Train/Batch_RMSE", metrics["rmse"], global_step)
-
-    # 8. è®¡ç®—epochçº§å¹³å‡æŒ‡æ ‡
-    avg_loss = total_loss / total_samples
-    avg_psnr = total_psnr / total_samples
-    avg_ssim = total_ssim / total_samples
-    avg_rmse = total_rmse / total_samples
-
-    # 9. è®°å½•epochçº§æ—¥å¿—ï¼ˆå†™å…¥TensorBoardï¼‰
-    writer.add_scalar("Train/Epoch_Loss", avg_loss, epoch)
-    writer.add_scalar("Train/Epoch_PSNR", avg_psnr, epoch)
-    writer.add_scalar("Train/Epoch_SSIM", avg_ssim, epoch)
-    writer.add_scalar("Train/Epoch_RMSE", avg_rmse, epoch)
-
-    return {
-        "loss": avg_loss,
-        "psnr": avg_psnr,
-        "ssim": avg_ssim,
-        "rmse": avg_rmse
-    }
-
-
-def validate(model, val_loader, criterion, metrics_fn, device, epoch, writer):
-    """éªŒè¯æ¨¡å‹ï¼Œè®¡ç®—æŸå¤±å’ŒæŒ‡æ ‡ï¼ŒåŒæ­¥è®°å½•å›¾åƒå¯¹æ¯”"""
-    model.eval()
-    # åˆå§‹åŒ–ç´¯è®¡å˜é‡
-    total_loss = 0.0
-    total_psnr = 0.0
-    total_ssim = 0.0
-    total_rmse = 0.0
-    total_samples = 0
-
-    # å…³é—­æ¢¯åº¦è®¡ç®—ï¼ˆåŠ é€ŸéªŒè¯ï¼Œé¿å…å†…å­˜å ç”¨ï¼‰
-    with torch.no_grad():
-        progress_bar = tqdm(val_loader, desc=f"[Val]   Epoch {epoch:3d}", unit="batch")
-        for batch_idx, (ld_img, nd_img) in enumerate(progress_bar):
-            ld_img = ld_img.to(device, non_blocking=True)
-            nd_img = nd_img.to(device, non_blocking=True)
-            batch_size = ld_img.size(0)
-            total_samples += batch_size
-
-            # 1. å‰å‘ä¼ æ’­
-            outputs = model(ld_img)
-
-            # 2. è®¡ç®—æŸå¤±å’ŒæŒ‡æ ‡
-            loss = criterion(outputs, nd_img)
-            metrics = metrics_fn(outputs, nd_img)
-
-            # 3. ç´¯è®¡æŸå¤±å’ŒæŒ‡æ ‡
-            total_loss += loss.item() * batch_size
-            total_psnr += metrics["psnr"] * batch_size
-            total_ssim += metrics["ssim"] * batch_size
-            total_rmse += metrics["rmse"] * batch_size
-
-            # 4. å®æ—¶æ›´æ–°è¿›åº¦æ¡
-            progress_bar.set_postfix({
-                "batch_loss": f"{loss.item():.6f}",
-                "batch_psnr": f"{metrics['psnr']:.2f}",
-                "batch_ssim": f"{metrics['ssim']:.4f}"
-            })
-
-            # 5. è®°å½•éªŒè¯é›†å›¾åƒå¯¹æ¯”ï¼ˆæ¯5ä¸ªepochï¼Œä»…å–ç¬¬ä¸€ä¸ªbatchçš„ç¬¬ä¸€å¼ å›¾ï¼‰
-            if epoch % 5 == 0 and batch_idx == 0:
-                # å›¾åƒå½’ä¸€åŒ–åˆ°[0,1]ï¼ˆTensorBoardæ˜¾ç¤ºéœ€è¦ï¼‰
-                def normalize_img(img_tensor):
-                    img = img_tensor.cpu().numpy()[0, 0]  # (B,1,H,W) â†’ (H,W)
-                    img_min, img_max = img.min(), img.max()
-                    return (img - img_min) / (img_max - img_min + 1e-8)  # é¿å…é™¤é›¶
-
-                # æå–å¹¶å½’ä¸€åŒ–3å¼ å›¾ï¼šä½å‰‚é‡è¾“å…¥ã€æ­£å¸¸å‰‚é‡æ ‡ç­¾ã€æ¨¡å‹è¾“å‡º
-                ld_img_norm = normalize_img(ld_img)
-                nd_img_norm = normalize_img(nd_img)
-                output_norm = normalize_img(outputs)
-
-                # å†™å…¥TensorBoardï¼ˆä¸‰å¼ å›¾æ¨ªå‘æ’åˆ—ï¼Œä¾¿äºå¯¹æ¯”ï¼‰
-                writer.add_image(f"Val/Epoch_{epoch}_LowDose", ld_img_norm, epoch, dataformats="HW")
-                writer.add_image(f"Val/Epoch_{epoch}_FullDose", nd_img_norm, epoch, dataformats="HW")
-                writer.add_image(f"Val/Epoch_{epoch}_ModelOutput", output_norm, epoch, dataformats="HW")
-
-    # 6. è®¡ç®—éªŒè¯é›†epochçº§å¹³å‡æŒ‡æ ‡
-    avg_loss = total_loss / total_samples
-    avg_psnr = total_psnr / total_samples
-    avg_ssim = total_ssim / total_samples
-    avg_rmse = total_rmse / total_samples
-
-    # 7. è®°å½•éªŒè¯é›†epochçº§æ—¥å¿—
-    writer.add_scalar("Val/Epoch_Loss", avg_loss, epoch)
-    writer.add_scalar("Val/Epoch_PSNR", avg_psnr, epoch)
-    writer.add_scalar("Val/Epoch_SSIM", avg_ssim, epoch)
-    writer.add_scalar("Val/Epoch_RMSE", avg_rmse, epoch)
-
-    return {
-        "loss": avg_loss,
-        "psnr": avg_psnr,
-        "ssim": avg_ssim,
-        "rmse": avg_rmse
-    }
-
-
-def main(args):
-    # 1. è®¾å¤‡é…ç½®ï¼ˆä¼˜å…ˆGPUï¼Œæ— GPUåˆ™ç”¨CPUï¼‰
-    device = torch.device(
-        f"cuda:{args.gpu}" if torch.cuda.is_available() and args.gpu >= 0 else "cpu"
-    )
-    print(f"=" * 60)
-    print(f"è®­ç»ƒé…ç½®ï¼š")
-    print(f"  è®¾å¤‡: {device}")
-    print(f"  æ•°æ®é›†æ ¹ç›®å½•: {args.data_dir}")
-    print(f"  è®­ç»ƒè½®æ•°: {args.epochs}")
-    print(f"  æ‰¹æ¬¡å¤§å°: {args.batch_size}")
-    print(f"  åˆå§‹å­¦ä¹ ç‡: {args.lr}")
-    print(f"  æ—¥å¿—ä¿å­˜ç›®å½•: {args.log_dir}")
-    print(f"  æ¨¡å‹ä¿å­˜ç›®å½•: {args.save_dir}")
-    print(f"=" * 60)
-
-    # 2. åŠ è½½æ•°æ®é›†ï¼ˆé€‚é…256Ã—256å›¾åƒï¼‰
-    print("\n[1/5] åŠ è½½æ•°æ®é›†...")
-    # ç”Ÿæˆè®­ç»ƒ/éªŒè¯é›†å›¾åƒå¯¹åˆ—è¡¨
-    train_pairs = get_pair_list(args.data_dir, split="train")
-    val_pairs = get_pair_list(args.data_dir, split="val")
-    # åˆå§‹åŒ–æ•°æ®é›†ï¼ˆæŒ‡å®šç›®æ ‡å°ºå¯¸256Ã—256ï¼‰
-    train_dataset = CTDataset(train_pairs, target_size=256)
-    val_dataset = CTDataset(val_pairs, target_size=256)
-    # æ„å»ºDataLoaderï¼ˆå¤šçº¿ç¨‹åŠ è½½ï¼Œpin_memoryåŠ é€ŸGPUä¼ è¾“ï¼‰
-    train_loader = DataLoader(
-        train_dataset,
-        batch_size=args.batch_size,
-        shuffle=True,
-        num_workers=args.num_workers,
-        pin_memory=True,
-        drop_last=True  # ä¸¢å¼ƒæœ€åä¸€ä¸ªä¸å®Œæ•´çš„batch
-    )
-    val_loader = DataLoader(
-        val_dataset,
-        batch_size=args.batch_size,
-        shuffle=False,
-        num_workers=args.num_workers,
-        pin_memory=True,
-        drop_last=False
-    )
-    print(f"  è®­ç»ƒé›†ï¼š{len(train_dataset)} æ ·æœ¬ | {len(train_loader)} æ‰¹æ¬¡")
-    print(f"  éªŒè¯é›†ï¼š{len(val_dataset)} æ ·æœ¬ | {len(val_loader)} æ‰¹æ¬¡")
-    print(f"  å›¾åƒå°ºå¯¸ï¼š{train_dataset[0][0].shape}ï¼ˆå·²Resizeåˆ°256Ã—256ï¼‰")
-
-    # 3. åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨ã€æŒ‡æ ‡è®¡ç®—å™¨
-    print("\n[2/5] åˆå§‹åŒ–æ¨¡å‹ä¸å·¥å…·...")
-
-    ########################################################################################################
-    # åˆå§‹åŒ–æ¨¡å‹ï¼ˆTransCTæ¨¡å‹ï¼‰
-    model = LDCTNet256().to(device)
-
-    # åˆå§‹åŒ–LDCTNet_Swinï¼ˆè¾“å…¥å°ºå¯¸256Ã—256ï¼Œä¸æ•°æ®é›†åŒ¹é…ï¼‰
-    # model = LDCTNet_Swin(
-    #     input_size=(256, 256),
-    #     base_channels=16,
-    #     swin_window_size=7,
-    #     swin_num_heads=8
-    # ).to(device)
-    # model = LDCTNet_Swin_improve().to(device)
-    # æ‰“å°æ¨¡å‹ä¿¡æ¯
-    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
-    print(f"æ¨¡å‹ç»“æ„:")
-    print(model)
-    #############################################################################################################
-
-    # æŸå¤±å‡½æ•°ï¼ˆMSEé€‚åˆCTå‰‚é‡æ¢å¤ï¼Œå¯åç»­æ›¿æ¢ä¸ºMSE+SSIMæ··åˆæŸå¤±ï¼‰
-    criterion = HybridLoss().to(device)
-
-    # ä¼˜åŒ–å™¨ï¼ˆAdam + æƒé‡è¡°å‡é˜²è¿‡æ‹Ÿåˆï¼‰
-    optimizer = optim.Adam(
-        model.parameters(),
-        lr=args.lr,
-        weight_decay=1e-5  # æƒé‡è¡°å‡ç³»æ•°ï¼Œå¯æ ¹æ®éœ€æ±‚è°ƒæ•´
-    )
-    # å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆéªŒè¯æŸå¤±ä¸ä¸‹é™æ—¶é™ä½å­¦ä¹ ç‡ï¼‰
-    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
-        optimizer,
-        mode="min",  # åŸºäº"éªŒè¯æŸå¤±"æœ€å°åŒ–è°ƒæ•´
-        factor=0.5,  # å­¦ä¹ ç‡é™ä½ä¸ºåŸæ¥çš„1/2
-        patience=3,  # è¿ç»­3ä¸ªepochæ— æ”¹å–„åˆ™è°ƒæ•´
-        min_lr=1e-7  # å­¦ä¹ ç‡ä¸‹é™
-    )
-    # æŒ‡æ ‡è®¡ç®—å™¨ï¼ˆdata_rangeéœ€ä¸é¢„å¤„ç†åå›¾åƒèŒƒå›´åŒ¹é…ï¼Œè¿™é‡Œå‡è®¾[0,1]ï¼‰
-    metrics_fn = ImageMetrics(data_range=1.0).to(device)
-
-    # 4. æ—¥å¿—ä¸æ¨¡å‹ä¿å­˜é…ç½®
-    print("\n[3/5] é…ç½®æ—¥å¿—ä¸æ¨¡å‹ä¿å­˜...")
-    # åˆ›å»ºæ—¥å¿—å’Œæ¨¡å‹ä¿å­˜ç›®å½•ï¼ˆä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»ºï¼‰
-    os.makedirs(args.log_dir, exist_ok=True)
-    os.makedirs(args.save_dir, exist_ok=True)
-    # åˆå§‹åŒ–TensorBoard writer
-    writer = SummaryWriter(log_dir=args.log_dir)
-
-    # æ–°å¢ï¼šåˆå§‹åŒ–è®­ç»ƒè®°å½•å™¨ï¼ˆä¿å­˜åˆ°log_dirä¸‹çš„metrics.csvï¼‰
-    recorder = TrainingRecorder(
-        save_path=os.path.join(args.log_dir, "training_metrics.csv"),
-        args=args  # ä¼ å…¥è®­ç»ƒå‚æ•°ï¼Œè®°å½•åˆ°CSVå¤´éƒ¨
-    )
-
-    # æœ€ä½³æ¨¡å‹è®°å½•ï¼ˆç”¨éªŒè¯é›†PSNRä½œä¸ºè¯„åˆ¤æ ‡å‡†ï¼ŒPSNRè¶Šé«˜æ¨¡å‹è¶Šå¥½ï¼‰
-    best_val_psnr = 0.0
-    best_val_epoch = 0
-
-    # 5. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¯é€‰ï¼Œæ”¯æŒæ–­ç‚¹ç»­è®­ï¼‰
-    if args.resume != "":
-        print(f"\n[4/5] åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼š{args.resume}")
-        if os.path.isfile(args.resume):
-            checkpoint = torch.load(args.resume, map_location=device)
-            # åŠ è½½æ¨¡å‹æƒé‡å’Œä¼˜åŒ–å™¨çŠ¶æ€
-            model.load_state_dict(checkpoint["model_state_dict"])
-            optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
-            # æ¢å¤è®­ç»ƒè¿›åº¦å’Œæœ€ä½³æŒ‡æ ‡
-            start_epoch = checkpoint["epoch"] + 1
-            best_val_psnr = checkpoint["best_val_psnr"]
-            best_val_epoch = checkpoint["best_val_epoch"]
-            print(f"  æ¢å¤è®­ç»ƒï¼šä»Epoch {start_epoch}å¼€å§‹")
-            print(f"  å†å²æœ€ä½³ï¼šEpoch {best_val_epoch} | Val PSNR: {best_val_psnr:.2f}")
-        else:
-            print(f"  è­¦å‘Šï¼šæœªæ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶ï¼Œå°†ä»å¤´å¼€å§‹è®­ç»ƒ")
-            start_epoch = 0
-    else:
-        start_epoch = 0
-
-    # 6. è®­ç»ƒä¸»å¾ªç¯
-    print("\n[5/5] å¼€å§‹è®­ç»ƒ...")
-    for epoch in range(start_epoch, args.epochs):
-        # è®­ç»ƒä¸€ä¸ªepoch
-        train_metrics = train_one_epoch(
-            model, train_loader, criterion, optimizer, metrics_fn, device, epoch, writer
-        )
-        # éªŒè¯ä¸€ä¸ªepoch
-        val_metrics = validate(
-            model, val_loader, criterion, metrics_fn, device, epoch, writer
-        )
-        # è°ƒæ•´å­¦ä¹ ç‡ï¼ˆåŸºäºéªŒè¯é›†æŸå¤±ï¼‰
-        scheduler.step(val_metrics["loss"])
-
-        # æ–°å¢ï¼šè®°å½•å½“å‰epochçš„å­¦ä¹ ç‡ï¼ˆç”¨äºCSVä¿å­˜ï¼‰
-        current_lr = optimizer.param_groups[0]["lr"]
-        # --------------------------
-        # æ–°å¢ï¼šæœ¬åœ°ä¿å­˜å›¾åƒå¯¹æ¯”ç½‘æ ¼
-        # --------------------------
-        save_freq = 3  # æ¯5ä¸ªepochä¿å­˜ä¸€æ¬¡ï¼ˆå¯è°ƒæ•´ä¸º1ã€10ç­‰ï¼‰
-        if epoch % save_freq == 0:
-            # è·å–ç¬¬ä¸€ä¸ªbatchçš„ç¬¬ä¸€ä¸ªæ ·æœ¬
-            val_first_batch = next(iter(val_loader))
-            ld_sample, nd_sample = val_first_batch
-            ld_sample = ld_sample.to(device, non_blocking=True)
-            nd_sample = nd_sample.to(device, non_blocking=True)
-
-            # æ¨¡å‹æ¨ç†ï¼ˆä»…å¯¹ç¬¬ä¸€ä¸ªæ ·æœ¬ï¼‰
-            model.eval()
-            with torch.no_grad():
-                output_sample = model(ld_sample)
-
-            # è°ƒç”¨ä¿å­˜å‡½æ•°ï¼ˆä¿å­˜è·¯å¾„ï¼šlog_dir/imagesï¼‰
-            save_image_grid(
-                ld_img=ld_sample,
-                nd_img=nd_sample,
-                output_img=output_sample,
-                save_path=os.path.join(args.image_dir, "images"),  # ä¿å­˜ç›®å½•
-                epoch=epoch
-            )
-        # --------------------------
-        # æ–°å¢ä»£ç ç»“æŸ
-        # --------------------------
-
-        # 7. æ§åˆ¶å°æ‰“å°epochæ€»ç»“ï¼ˆæ ¼å¼åŒ–è¾“å‡ºï¼Œæ¸…æ™°æ˜“è¯»ï¼‰
-        print(f"\n" + "=" * 80)
-        print(f"Epoch {epoch:3d}/{args.epochs - 1:3d} | è®­ç»ƒé›†æŒ‡æ ‡ï¼š")
-        print(f"  æŸå¤±ï¼š{train_metrics['loss']:.6f} | PSNRï¼š{train_metrics['psnr']:.2f} dB")
-        print(f"  SSIMï¼š{train_metrics['ssim']:.4f} | RMSEï¼š{train_metrics['rmse']:.6f}")
-        print(f"Epoch {epoch:3d}/{args.epochs - 1:3d} | éªŒè¯é›†æŒ‡æ ‡ï¼š")
-        print(f"  æŸå¤±ï¼š{val_metrics['loss']:.6f} | PSNRï¼š{val_metrics['psnr']:.2f} dB")
-        print(f"  SSIMï¼š{val_metrics['ssim']:.4f} | RMSEï¼š{val_metrics['rmse']:.6f}")
-        print(f"=" * 80)
-
-        # æ–°å¢ï¼šè°ƒç”¨recorderè®°å½•æŒ‡æ ‡åˆ°CSV
-        recorder.record_epoch(epoch, train_metrics, val_metrics, current_lr)
-
-        # 8. ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆéªŒè¯é›†PSNRæ›´é«˜åˆ™æ›´æ–°ï¼‰
-        if val_metrics["psnr"] > best_val_psnr:
-            best_val_psnr = val_metrics["psnr"]
-            best_val_epoch = epoch
-            # ä¿å­˜æ¨¡å‹æƒé‡ã€ä¼˜åŒ–å™¨çŠ¶æ€ã€è®­ç»ƒè¿›åº¦
-            checkpoint = {
-                "epoch": epoch,
-                "model_state_dict": model.state_dict(),
-                "optimizer_state_dict": optimizer.state_dict(),
-                "best_val_psnr": best_val_psnr,
-                "best_val_epoch": best_val_epoch,
-                "val_metrics": val_metrics  # ä¿å­˜å½“å‰éªŒè¯é›†æŒ‡æ ‡
-            }
-            best_model_path = os.path.join(args.save_dir, "best_model.pth")
-            torch.save(checkpoint, best_model_path)
-            print(f"[ä¿å­˜æœ€ä½³æ¨¡å‹] Epoch {epoch} | éªŒè¯é›†PSNRï¼š{best_val_psnr:.2f} dB")
-
-        # 9. ä¿å­˜å®šæœŸ checkpointï¼ˆæ¯10ä¸ªepochä¿å­˜ä¸€æ¬¡ï¼Œä¾¿äºå›æº¯ï¼‰
-        if (epoch + 1) % 50 == 0:
-            checkpoint = {
-                "epoch": epoch,
-                "model_state_dict": model.state_dict(),
-                "optimizer_state_dict": optimizer.state_dict(),
-                "val_metrics": val_metrics
-            }
-            checkpoint_path = os.path.join(args.save_dir, f"checkpoint_epoch_{epoch}.pth")
-            torch.save(checkpoint, checkpoint_path)
-            print(f"[ä¿å­˜å®šæœŸ checkpoint] Epoch {epoch} | è·¯å¾„ï¼š{checkpoint_path}")
-
-    # 10. è®­ç»ƒç»“æŸï¼šæ‰“å°æ€»ç»“å¹¶å…³é—­writer
-    print("\n" + "=" * 60)
-    print("è®­ç»ƒå®Œæˆï¼")
-    print(f"æœ€ä½³æ¨¡å‹ï¼šEpoch {best_val_epoch} | éªŒè¯é›†PSNRï¼š{best_val_psnr:.2f} dB")
-    print(f"æœ€ä½³æ¨¡å‹è·¯å¾„ï¼š{os.path.join(args.save_dir, 'best_model.pth')}")
-    writer.close()
-    print("TensorBoard æ—¥å¿—å·²ä¿å­˜åœ¨ï¼š{}".format(args.log_dir))
-
-
-if __name__ == "__main__":
-    parser = argparse.ArgumentParser()
-    parser.add_argument("--data_dir", type=str, default="./ND_LD_Paired_Data")
-    parser.add_argument("--epochs", type=int, default=300)
-    parser.add_argument("--batch_size", type=int, default=8)
-    parser.add_argument("--lr", type=float, default=1e-4)
-    parser.add_argument("--log_dir", type=str, default="./logs")
-    parser.add_argument("--image_dir", type=str, default="./image_loader")
-    parser.add_argument("--save_dir", type=str, default="./checkpoints")
-    parser.add_argument("--num_workers", type=int, default=4)
-    parser.add_argument("--gpu", type=int, default=0)
-    parser.add_argument("--resume", type=str, default="")
-    args = parser.parse_args()
-    main(args)
Index: SwinTransCT-main/utils.py
===================================================================
diff --git a/SwinTransCT-main/utils.py b/SwinTransCT-main/utils.py
deleted file mode 100644
--- a/SwinTransCT-main/utils.py	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
+++ /dev/null	(revision 7a4bc7d60dc78b00aa690a7d9b931c88b34458fb)
@@ -1,175 +0,0 @@
-import csv
-import math
-import os
-
-import torch
-import torch.nn.functional as F
-from torch import nn
-
-
-def calculate_psnr(img1, img2, data_range=1.0):
-    """
-    è®¡ç®— PSNRï¼ˆå³°å€¼ä¿¡å™ªæ¯”ï¼‰
-    :param img1: é¢„æµ‹å›¾åƒå¼ é‡ (B, C, H, W)
-    :param img2: çœŸå®å›¾åƒå¼ é‡ (B, C, H, W)
-    :param data_range: å›¾åƒæ•°æ®èŒƒå›´ï¼ˆé»˜è®¤1.0ï¼Œéœ€ä¸é¢„å¤„ç†åçš„å›¾åƒèŒƒå›´åŒ¹é…ï¼‰
-    :return: æ‰¹é‡å›¾åƒçš„å¹³å‡ PSNR
-    """
-    # è®¡ç®— MSEï¼ˆå‡æ–¹è¯¯å·®ï¼‰
-    mse = F.mse_loss(img1, img2, reduction='mean')
-    if mse == 0:
-        return float('inf')  # MSEä¸º0æ—¶PSNRæ— ç©·å¤§
-    # PSNRå…¬å¼ï¼šPSNR = 10 * log10((data_range^2) / MSE)
-    psnr = 10 * torch.log10((data_range ** 2) / mse)
-    return psnr.item()
-
-
-def calculate_ssim(img1, img2, data_range=1.0, window_size=11, window_sigma=1.5):
-    """
-    è®¡ç®— SSIMï¼ˆç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼‰
-    å‚è€ƒ PyTorch å®˜æ–¹å®ç°æ€è·¯ï¼Œé€‚é…æ‰¹é‡å›¾åƒ
-    :param img1: é¢„æµ‹å›¾åƒå¼ é‡ (B, C, H, W)
-    :param img2: çœŸå®å›¾åƒå¼ é‡ (B, C, H, W)
-    :param data_range: å›¾åƒæ•°æ®èŒƒå›´ï¼ˆé»˜è®¤1.0ï¼‰
-    :param window_size: é«˜æ–¯çª—å£å¤§å°ï¼ˆé»˜è®¤11ï¼Œéœ€ä¸ºå¥‡æ•°ï¼‰
-    :param window_sigma: é«˜æ–¯çª—å£æ ‡å‡†å·®ï¼ˆé»˜è®¤1.5ï¼‰
-    :return: æ‰¹é‡å›¾åƒçš„å¹³å‡ SSIM
-    """
-    device = img1.device
-    C1 = (0.01 * data_range) ** 2  # ç¨³å®šæ€§å¸¸æ•°1
-    C2 = (0.03 * data_range) ** 2  # ç¨³å®šæ€§å¸¸æ•°2
-
-    # ç”Ÿæˆ1Dé«˜æ–¯çª—å£
-    gauss = torch.Tensor([math.exp(-(x - window_size // 2) ** 2 / (2 * window_sigma ** 2))
-                          for x in range(window_size)]).to(device)
-    gauss = gauss / gauss.sum()  # å½’ä¸€åŒ–
-
-    # æ‰©å±•ä¸º2Dçª—å£ï¼ˆ1, 1, window_size, window_sizeï¼‰
-    window = gauss.unsqueeze(1) @ gauss.unsqueeze(0)
-    window = window.unsqueeze(0).unsqueeze(0).expand(img1.shape[1], 1, window_size, window_size)
-
-    # è®¡ç®—å›¾åƒå‡å€¼ï¼ˆé«˜æ–¯æ»¤æ³¢ï¼‰
-    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=img1.shape[1])
-    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=img2.shape[1])
-
-    # è®¡ç®—å›¾åƒæ–¹å·®å’Œåæ–¹å·®
-    mu1_sq = mu1 ** 2
-    mu2_sq = mu2 ** 2
-    mu1_mu2 = mu1 * mu2
-
-    sigma1_sq = F.conv2d(img1 ** 2, window, padding=window_size // 2, groups=img1.shape[1]) - mu1_sq
-    sigma2_sq = F.conv2d(img2 ** 2, window, padding=window_size // 2, groups=img2.shape[1]) - mu2_sq
-    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=img1.shape[1]) - mu1_mu2
-
-    # SSIMå…¬å¼
-    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))
-    return ssim_map.mean().item()  # æ‰¹é‡å¹³å‡
-
-
-def calculate_rmse(img1, img2):
-    """
-    è®¡ç®— RMSEï¼ˆå‡æ–¹æ ¹è¯¯å·®ï¼‰
-    :param img1: é¢„æµ‹å›¾åƒå¼ é‡ (B, C, H, W)
-    :param img2: çœŸå®å›¾åƒå¼ é‡ (B, C, H, W)
-    :return: æ‰¹é‡å›¾åƒçš„å¹³å‡ RMSE
-    """
-    # RMSEå…¬å¼ï¼šRMSE = sqrt(MSE)
-    mse = F.mse_loss(img1, img2, reduction='mean')
-    rmse = torch.sqrt(mse)
-    return rmse.item()
-
-
-class TrainingRecorder:
-    """
-    è®­ç»ƒè¿‡ç¨‹è®°å½•å™¨ï¼šå°†æ¯ä¸ªepochçš„è®­ç»ƒ/éªŒè¯æŒ‡æ ‡ä¿å­˜åˆ°CSVæ–‡ä»¶
-    æ”¯æŒæ–­ç‚¹ç»­è®­æ—¶è‡ªåŠ¨ç»­å†™ï¼Œé¿å…æ•°æ®ä¸¢å¤±
-    """
-
-    def __init__(self, save_path, args=None):
-        """
-        Args:
-            save_path: CSVæ–‡ä»¶ä¿å­˜è·¯å¾„ï¼ˆå¦‚"logs/training_metrics.csv"ï¼‰
-            args: è®­ç»ƒå‚æ•°ï¼ˆå¯é€‰ï¼Œç”¨äºè®°å½•è®­ç»ƒé…ç½®åˆ°CSVå¤´éƒ¨ï¼‰
-        """
-        self.save_path = save_path
-        self._init_csv(args)
-
-    def _init_csv(self, args):
-        """åˆå§‹åŒ–CSVæ–‡ä»¶ï¼šè‹¥ä¸å­˜åœ¨åˆ™åˆ›å»ºå¹¶å†™å…¥è¡¨å¤´ï¼Œè‹¥å­˜åœ¨åˆ™è·³è¿‡è¡¨å¤´"""
-        # åˆ›å»ºçˆ¶ç›®å½•ï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰
-        os.makedirs(os.path.dirname(self.save_path), exist_ok=True)
-
-        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
-        file_exists = os.path.isfile(self.save_path)
-
-        with open(self.save_path, 'a', newline='', encoding='utf-8') as f:
-            writer = csv.DictWriter(f, fieldnames=[
-                "epoch", "train_loss", "train_psnr", "train_ssim", "train_rmse",
-                "val_loss", "val_psnr", "val_ssim", "val_rmse", "lr", "timestamp"
-            ])
-
-            # è‹¥æ–‡ä»¶æ–°åˆ›å»ºï¼Œå…ˆå†™å…¥è®­ç»ƒé…ç½®å’Œè¡¨å¤´
-            if not file_exists:
-                # å†™å…¥è®­ç»ƒå‚æ•°é…ç½®ï¼ˆä¾¿äºåç»­å¤ç°å®éªŒï¼‰
-                if args is not None:
-                    f.write("# è®­ç»ƒé…ç½®å‚æ•°\n")
-                    for key, value in vars(args).items():
-                        f.write(f"# {key}: {value}\n")
-                    f.write("# \n")  # ç©ºè¡Œåˆ†éš”é…ç½®å’Œæ•°æ®
-
-                # å†™å…¥æŒ‡æ ‡è¡¨å¤´
-                writer.writeheader()
-
-    def record_epoch(self, epoch, train_metrics, val_metrics, current_lr):
-        """
-        è®°å½•å•ä¸ªepochçš„æŒ‡æ ‡åˆ°CSVæ–‡ä»¶
-        Args:
-            epoch: å½“å‰epochç¼–å·ï¼ˆintï¼‰
-            train_metrics: è®­ç»ƒé›†æŒ‡æ ‡å­—å…¸ï¼ˆæ¥è‡ªtrain_one_epochè¿”å›å€¼ï¼‰
-            val_metrics: éªŒè¯é›†æŒ‡æ ‡å­—å…¸ï¼ˆæ¥è‡ªvalidateè¿”å›å€¼ï¼‰
-            current_lr: å½“å‰å­¦ä¹ ç‡ï¼ˆfloatï¼‰
-        """
-        # æ„å»ºæŒ‡æ ‡å­—å…¸ï¼ˆä¸CSVè¡¨å¤´å¯¹åº”ï¼‰
-        metrics_dict = {
-            "epoch": epoch,
-            "train_loss": round(train_metrics["loss"], 6),
-            "train_psnr": round(train_metrics["psnr"], 4),
-            "train_ssim": round(train_metrics["ssim"], 6),
-            "train_rmse": round(train_metrics["rmse"], 6),
-            "val_loss": round(val_metrics["loss"], 6),
-            "val_psnr": round(val_metrics["psnr"], 4),
-            "val_ssim": round(val_metrics["ssim"], 6),
-            "val_rmse": round(val_metrics["rmse"], 6),
-            "lr": round(current_lr, 8)
-        }
-
-        # è¿½åŠ å†™å…¥CSV
-        with open(self.save_path, 'a', newline='', encoding='utf-8') as f:
-            writer = csv.DictWriter(f, fieldnames=metrics_dict.keys())
-            writer.writerow(metrics_dict)
-
-        # æ‰“å°è®°å½•æç¤ºï¼ˆå¯é€‰ï¼‰
-        print(f"[æŒ‡æ ‡è®°å½•] Epoch {epoch} æŒ‡æ ‡å·²ä¿å­˜åˆ° {self.save_path}")
-
-
-# å°è£…æŒ‡æ ‡è®¡ç®—ç±»ï¼ˆæ–¹ä¾¿è®­ç»ƒä¸­è°ƒç”¨ï¼‰
-class ImageMetrics(nn.Module):
-    def __init__(self, data_range=1.0):
-        super().__init__()
-        self.data_range = data_range
-
-    def forward(self, pred, target):
-        """
-        ä¸€æ¬¡æ€§è®¡ç®— PSNRã€SSIMã€RMSE
-        :param pred: é¢„æµ‹å›¾åƒ (B, C, H, W)
-        :param target: çœŸå®å›¾åƒ (B, C, H, W)
-        :return: metrics_dictï¼ˆåŒ…å«ä¸‰ä¸ªæŒ‡æ ‡çš„æ•°å€¼ï¼‰
-        """
-        psnr = calculate_psnr(pred, target, self.data_range)
-        ssim = calculate_ssim(pred, target, self.data_range)
-        rmse = calculate_rmse(pred, target)
-        return {
-            'psnr': psnr,
-            'ssim': ssim,
-            'rmse': rmse
-        }
